--- 
title: "Workshop 9: Multivariate Analyses in `R`"
subtitle: "QCBS R Workshop Series"
author:
- Developed and maintained by the contributors of the QCBS R Workshop Series^[The QCBS R Workshop Series is part of the [Québec Centre for Biodiversity Science](https://www.qcbs.ca), and is maintained by the series coordinators and graduent student, postdoctoral, and research professional members. **The contributors for this workshop can be accessed [here](link)**.]
date: "`r Sys.time()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: ["references.bib"]
biblio-style: apalike
link-citations: yes
cover-image: assets/images/logo/csbq_logo_accueil.png
github-repo: "qcbsRworkshops/workshop09"
description: "Multivariate Analyses in `R`"
favicon: "assets/images/favicon.ico"
always_allow_html: yes
url: 'https\://github.com/qcbsRworkshops/'
config:
  edit:
    link: https://github.com/qcbsRworkshops/workshop09/edit/main/book-en/%s
    text: "Suggest changes"
---

# (PART\*) QCBS R Workshop Series {-}
# Preface {-}

Placeholder


## Code of conduct
### Expected behaviour
### Unacceptable behaviour
## Contributors
## Contributing

<!--chapter:end:index.Rmd-->


# (PART\*) Multivariate Analyses in `R` {-}
# Learning objectives

Placeholder



<!--chapter:end:01-preparing-for-the-workshop.Rmd-->


# (PART\*) PREAMBLE {-}
# Recap: Univariate analyses

Placeholder



<!--chapter:end:02-introduction.Rmd-->


# Matrix algebra, very briefly

Placeholder


## Data sets _are_ matrices
## Association matrices
## Doubs river fish communities 
## Doubs river environmental data

<!--chapter:end:03-data-exploration.Rmd-->

# (PART\*) (Dis)similarity measures {-}

# `dist()` 

Community resemblance is almost always assessed on the basis of species composition data in the form of a site-by-species data table $Y_{m,n}$.

We can obtain an association matrix $A_{m,m}$ in the form of pairwise distances or dissimilarities $D_{m,m}$ (or similarities $S_{m,m}$) and then analyse those distances. Association matrices between objects or among descriptors allow for
calculations of similarity or distances between objects or descriptors
(Legendre and Legendre 2012). 

In `R`, we can compute distance or dissimilarity matrices using `stats::dist()`. 
For simplicity, let us do this without specifying arguments:

```{r, eval = T, results='hide'}
dist(spe)
```

Run `dist(spe)` from your end, and you should observe that the output from `dist(spe) is a _lower triangular matrix_ representing pairwise associations between the columns of your original matrix.

Let us see what the commands below show us:

```{r, eval = T}
class(dist(spe))
```

The output from `dist()` is a `dist` class object by default. 
This object is composed of a vector that contains the lower triangle of the distance matrix, distributed across columns.
You can coerce it into a matrix with `as.matrix()`, as seen below:

```{r, eval = F}
as.matrix(dist(spe))
```

Notably, you can coerce a matrix that contains distances ($D_{m,m}$) using `as.dist()`.

You can also explore the structure and dimensions of our `dist`-class object and distance matrix:

```{r, eval = F}
str(dist(spe))
```

```{r, eval = T}
dim(as.matrix(dist(spe)))
```

# Types of distance coefficients

There are three groups of distance coefficients: _metrics_, _semimetrics_, and _nonmetrics_ .

## Metric distances

The first group consists of *metrics*, and its coefficients satisfy the following properties:

1. minimum 0: if species $a$ is equal to species $b$, then $D(a,b)=0$; ✅

2. positiveness: if $a \neq b$, then $D(a,b) > 0$; ✅

3. symmetry: $D(a,b) = D(b,a)$; ✅

4. triangle inequality: $D(a,b) + D(b,c) \geq D(a,c)$. The sum of two sides of a triangle drawn in the Euclidean space is equal or greater than the third side. ✅

We can spot all these properties below:

```{r, eval = T}
as.matrix(dist(spe))[1:6, 1:6]
```

### Euclidean distances

The most common metric distance measure is the _Euclidean distance_.

Euclidean distance is a measure of the distance between two points in Euclidean space. 
In two dimensions, the Euclidean distance between two points (x1, y1) and (x2, y2) can be calculated using the Pythagorean theorem:

$$D_{1} (x_1,x_2) = \sqrt{\sum_{j=1}^p(y_{1j} - y_{2j})^2}$$

```{r echo=FALSE}
#setting up the plot
xlim <- c(0,4)
ylim <- c(-1,5)
par(mar=c(1,1,1,1)+.1)
plot(xlim, 
     ylim, type="n", 
     xlab="X1", 
     ylab="X2", 
     asp=1)
grid()
# define some vectors
a=c(4, 0)
b=c(0, 4)
# plot the vectors
vectors(a, labels="D(y21, y11)", pos.lab=3, frac.lab=.5, col="grey")
vectors(a + b, labels="D1(x1,x2)", pos.lab=4, frac.lab=.5, col="red")
# vector a+b starting from a is equal to b.
vectors(a + b, labels="D(y12, y22)", pos.lab=4, frac.lab=.5, origin=a, col="grey")

points(x = 4, y = 0, type = "p")
text(x=4.1, y=-0.2, labels="")

points(x = 0, y = 0, type = "p")
text(x=-0.1, y=-0.2, labels="x1")

points(x = 4, y = 4, type = "p")
text(x=4.1, y=4.2, labels="x2")
```

Euclidean distance is a commonly used measure in multivariate analyses because it provides a straightforward and intuitive way to measure the distance or similarity between observations in a multidimensional space. 

Using `stats::dist()`, we can compute it with:

```{r, eval = T}
spe.D.Euclid <- dist(x = spe,  
                     method = "euclidean")
```

And, we can test whether a distance is Euclidean using:

```{r, eval = T}
is.euclid(spe.D.Euclid)
```

### Challenge #1

**Your turn!** Using the `dist()` function, compute the Euclidean distance matrix $D_{hmm}$ for the species abundances by site matrix $Y_{hmm}$ below:

| Sites | $y_1$ | $y_2$ | $y_3$ |
|:----: | :----:| :---: | :---: |
| $s_1$ | 0 | 4 | 8 |
| $s_2$ | 0 | 1 | 1 |
| $s_3$ | 1 | 0 | 0 |

```{r, eval = T}
Y.hmm <- data.frame(
  y1 = c(0, 0, 1),
  y2 = c(4, 1, 0),
  y3 = c(8, 1, 0))
```

After this, look into the numbers, think critically about them!

**Solution:**

You should have something similar to this:

```{r, eval = T}
Y.hmm.DistEu <- dist(x = Y.hmm,  
                     method = "euclidean")

as.matrix(Y.hmm.DistEu)
```

_Now, look into the composition and the distances between sites $s_2$ and $s_3$ and between $s_1$ and $s_2$. What is going on?_

The Euclidean distance between sites $s_2$ and $s_3$, which have no species in common, is smaller than the distance between $s_1$ and $s_2$, which share species $y_2$ and $y_3$ (!).

From an ecological perspective, _this is a problematic_ assessment of the relationship among sites.

This issue is known as the **double-zero problem**, _i.e._ double zeroes are treated in the same way as double presences, so that the double zeros shrink the distance between two sites.

Euclidean distances ( $D_1$ ) should thus _not_ be used to compare sites based on species abundances.

### Chord distances

Orlóci (1967) proposed the _Chord distance_ to analyse community composition. 

Chord distance, also known as angular distance or great-circle distance, is a measure of the distance between two points on a sphere, such as the Earth. 

It consists of:

1\. Normalizing the data, _i.e._ scaling site vectors to length 1 by dividing species abundances in a given sample by the square-rooted sum of square abundances in all samples as

$$y'_{Uj}=y_{Uj}/\sum^s_{j=1}{y^2_{Uj}}$$

2\. Calculating the Euclidean distances on this normalized data:

$$D_{3} (x_1,x_2) = \sqrt{\sum_{j=1}^p(y'_{1j} - y'_{2j})^2}$$

We can use `vegan::vegdist()` for this one:

```{r, eval = T}
spe.D.Ch <- vegdist(spe,  
                    method = "chord")

as.matrix(spe.D.Ch)[1:3, 1:3]
```

When two sites share the same species in the same proportions of the number of individuals the value of $D_3$ is $0$, and when no species are shared, its value is $\sqrt{2}$. 

_What happens if we compute Chord distances in the same site-by-species matrix $Y_{hmm}$?_

Let us try the Chord distances in the same matrix we used for Challenge #1:

```{r, eval = T}
Y.hmm.DistCh <- vegdist(Y.hmm,  
                    method = "chord")
```

```{r echo=TRUE}
as.matrix(Y.hmm.DistCh)
```

Now, let us compare with what we obtained when we used Euclidean distances:

```{r echo=TRUE}
as.matrix(Y.hmm.DistEu)
```

See again how our matrix looks:

```{r, eval = T}
Y.hmm
```

So, adding any number of double zeroes to a pair of sites does _not_ change the value of $D_3$. Hence, _Chord distances_ can be used to compare sites described by species abundances!

### Jaccard's coefficient

Another popular association coefficient is the _Jaccard similarity coefficient_ (1900).

The Jaccard similarity coefficient was originally proposed by the French mathematician Paul Jaccard in 1901, in the context of ecology. 
Jaccard was interested in comparing the species composition of different plant communities, and proposed the Jaccard index as a measure of similarity between two communities based on their species richness.

Jaccard's similarity coefficient is only appropriate for **binary data**, and its distance coefficient is defined with the size of the intersection divided by the size of the union of the sample sets.

$$D_{7}(x_1,x_2) = 1 - \frac{\vert x_1 \cap x_2 \vert}{\vert x_1 \cup x_2 \vert} = 1 - \frac{\vert x_1 \cap x_2 \vert}{\vert x_1 \vert + \vert x_2 \vert - \vert x_1 \cap x_2 \vert} = 1-\frac{a}{a+b+c}$$
  
where,

- $a$ is the number of species shared between $x_1$ and $x_2$ that are coded $1$;
- $b$ is the number of occurrences where $x_1$ and $x_2$ are known to be different;
- $c$ is the number of common absences between $x_1$ and $x_2$, _i.e._ both $0$. 

For example, for sites $x_1$ and $x_2$:

| $x_1,x_2$ | $y_1$ | $y_2$ | $y_3$ | $y_4$ | $y_5$ |
|:----: | :----:| :---: | :---: | :---: | :---: |
| $x_1$ | 0 | 1 | 0 | 1 | 0 |
| $x_2$ | 0 | 1 | 1 | 1 | 1 |

So, we can calculate $a$, $b$, and $c$:
- $a$ = 1 + 1 = 2

- $b$ = 1 + 1 = 2

- $c$ = 1

And, then our distance coefficient:

$$D_{7}(x_1,x_2) = 1-\frac{2}{2+2+1}= 0.6$$

In `R`, you can use use the `vegan::vegdist()` function to calculate the Jaccard's coefficient:

```{r}
spe.D.Jac <- vegdist(spe, 
                     method = "jaccard",
                     binary = TRUE)
```

## Semimetric distances

The second group consists of *semimetrics*, and they violate the _triangle inequality_ property:

1. minimum 0: if species $a$ is equal to species $b$, then $D(a,b)=0$; ✅

2. positiveness: if $a \neq b$, then $D(a,b) > 0$; ✅

3. symmetry: $D(a,b) = D(b,a)$; ✅

4. ~~triangle inequality~~: ${D(a,b) + D(b,c) \geq or < D(a,c)}$. The sum of two sides of a triangle drawn in the Euclidean space is _not_ equal or greater than the third side. ❌

### Sørensen's coefficient

All parameters in _Jaccard's similarity coefficient_ have equal weights.

$$D_{7}(x_1,x_2)=1-\frac{a}{a+b+c}$$

However, you may want to consider that a presence of a species is more informative than its absence.

The distance corresponding to _Sørensen's similarity coefficient_ (1948) gives weight to double presences:

$$D_{13}(x_1,x_2)=1-\frac{2a}{2a+b+c}=\frac{b+c}{2a+b+c}$$

where,

- $a$ is the number of species shared between $x_1$ and $x_2$ that are coded $1$;
- $b$ is the number of occurrences where $x_1$ and $x_2$ are known to be different;
- $c$ is the number of common absences between $x_1$ and $x_2$, _i.e._ both $0$. 


In `R`, you can also use use the `vegan::vegdist()` function to calculate the Sørensen's coefficient:

```{r}
spe.D.Sor <- vegdist(spe, 
                     method = "bray",
                     binary = TRUE)
```

> Because both Jaccard's and Sørensen's are only appropriate for presence-absence data, you must binary-transform abundance data using `binary = TRUE` in `vegdist()`.

### Bray-Curtis' coefficient

The _Bray-Curtis dissimilarity coefficient_ is a modified version of the Sørensen's index and allows for species abundances:

$$D_{14}(x_1,x_2)=\frac{\sum{\vert y_{1j}-y_{2j}\vert}}{\sum{( y_{1j}+y_{2j})}}=$$

$$D_{14}(x_1,x_2)=1 - \frac{2W}{A+B}$$

where,

- $W$ is the sum of the lowest abundances in each species found between sites $x_1$ and $x_2$;

- $A$ is the sum of all abundances in $x_1$; and,

- $B$ is the sum of all abundances in $x_2$.

For example, for sites $x_1$ and $x_2$:

| $x_1,x_2$ | $y_1$ | $y_2$ | $y_3$ | $y_4$ | $y_5$ |
|:----: | :----:| :---: | :---: | :---: | :---: |
| $x_1$ | _2_ | _1_ | _0_ | 5 | 2 |
| $x_2$ | 5 | _1_ | 3 | _1_ | 1 |


So:

- $W = 2 + 1 + 0 + 1 + 1 = 5$

- $A = 2 + 1 + 0 + 5 + 0 = 8$

- $B = 5 + 1 + 3 + 1 + 2 = 12$

$$D_{14}(x_1,x_2) = 1-\frac{2 \times 5}{8+12} = 0.5$$

To calculate the _Bray-Curtis dissimilarity coefficient_, which can account for abundances, you need to set `binary = FALSE`.

```{r}
spe.db.pa <- vegdist(spe, 
                      method = "bray",
                      binary = FALSE)
spe.db <- as.matrix(spe.db.pa)
```

## Nonmetric distances

Non-metric distances do not satisfy the metric properties of symmetry, triangle inequality, and identity of indiscernibles: 

1. minimum 0: if species $a$ is equal to species $b$, then $D(a,b)=0$; ✅

2. ~~positiveness:~~ if $a \neq b$, then $D(a,b) > or < 0$; ❌

3. symmetry: $D(a,b) = D(b,a)$; ✅

4. ~~triangle inequality~~: ${D(a,b) + D(b,c) \geq or < D(a,c)}$. The sum of two sides of a triangle drawn in the Euclidean space is _not_ equal or greater than the third side. ❌

## Representing distance matrices

We can create graphical depictions of association matrices using the `coldiss()` function:

```{r, echo = FALSE}
# coldiss() function
# Color plots of a dissimilarity matrix, without and with ordering
#
# License: GPL-2 
# Author: Francois Gillet, 23 August 2012
#

"coldiss" <- function(D, nc = 4, byrank = TRUE, diag = FALSE)
{
  require(gclus)
  
  if (max(D)>1) D <- D/max(D)
  
  if (byrank) {
    spe.color <- dmat.color(1-D, cm.colors(nc))
  }
  else {
    spe.color <- dmat.color(1-D, byrank=FALSE, cm.colors(nc))
  }
  
  spe.o <- order.single(1-D)
  speo.color <- spe.color[spe.o, spe.o]
  
  op <- par(mfrow=c(1,2), pty="s")
  
  if (diag) {
    plotcolors(spe.color, rlabels=attributes(D)$Labels, 
               main="Dissimilarity Matrix", 
               dlabels=attributes(D)$Labels)
    plotcolors(speo.color, rlabels=attributes(D)$Labels[spe.o], 
               main="Ordered Dissimilarity Matrix", 
               dlabels=attributes(D)$Labels[spe.o])
  }
  else {
    plotcolors(spe.color, rlabels=attributes(D)$Labels, 
               main="Dissimilarity Matrix")
    plotcolors(speo.color, rlabels=attributes(D)$Labels[spe.o], 
               main="Ordered Dissimilarity Matrix")
  }
  
  par(op)
}

# Usage:
# coldiss(D = dissimilarity.matrix, nc = 4, byrank = TRUE, diag = FALSE)
# If D is not a dissimilarity matrix (max(D) > 1), then D is divided by max(D)
# nc 							number of colours (classes)
# byrank= TRUE		equal-sized classes
# byrank= FALSE		equal-length intervals
# diag = TRUE			print object labels also on the diagonal

# Example:
# coldiss(spe.dj, nc=9, byrank=F, diag=T)

```

# Mahalanobis distance

The Mahalanobis distance between a point $x$ and a group of points with mean $\mu$ and covariance $\Sigma$ is defined as:

$$
D_{M}(x, \mu)=\sqrt{(x-\mu)^{T} \Sigma^{-1}(x-\mu)}
$$
 
where $T$ denotes the transpose, and $\Sigma^{-1}$ is the inverse (or generalized inverse) of the covariance matrix $\Sigma$.

The Mahalanobis distance is a measure of the distance between a point and a group of points, taking into account the covariance structure of the data. 

The inverse of the covariance matrix may not exist in some cases, such as when the variables are linearly dependent or when there are more variables than observations. In these cases, we can use the generalized inverse of the covariance matrix instead of the inverse to calculate the Mahalanobis distance.
This generalized inverse can be calculated using various methods, such as the Moore-Penrose pseudoinverse or the singular value decomposition.

```{r}
# Create a matrix
x <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9), ncol = 3)

# Compute the covariance matrix and its generalized inverse
cov_mat <- cov(x)
cov_inv <- ginv(cov_mat)

# Compute the Mahalanobis distance using the generalized inverse
mah_dist <- mahalanobis(x, 
                        colMeans(x), 
                        cov_inv)

# Print the Mahalanobis distance
mah_dist

```



```{r, fig.height = 8, fig.width = 16}
coldiss(spe.D.Jac)
```

You can also use `ggplot2::ggplot()` to represent your matrix using a `geom_tile()` object:

```{r,  fig.height = 8, fig.width = 9}
# obtain the order of the rows and columns
order_spe.D.Jac <- hclust(spe.D.Jac, method = "complete")$order

# reorder the matrix to produce an figure ordered by similarities
order_spe.D.Jac_matrix <- as.matrix(spe.D.Jac)[order_spe.D.Jac, order_spe.D.Jac]

# converts to data frame
molten_spe.D.Jac <- reshape2::melt(
  as.matrix(order_spe.D.Jac_matrix)
  )

# create ggplot object
ggplot(data = molten_spe.D.Jac, 
       aes(x = Var1, y = Var2, 
           fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "black") +
  theme_minimal()
```

# Transformations

Communities sampled over homogeneous or short environmental conditions can have species compositions with few zeroes, so that Euclidean distances could be enough to characterize them.

Nevertheless, this is rarely the reality. 

Species may be highly frequent when conditions are favourable, or may be absent from many sites. Sometimes, this skewness may introduce spurious problems to our analyses.

We may then have to transform our composition data to appropriately analyze it.


In `R`, we can rely on `vegan::decostand()` for many types of transformations. 

Take a look into the help of this function to see the available options:

```
?decostand()
```

## Presence-absence transformation

We can change the argument `method` to `"pa"` in `vegdist()` to transform our abundance data into presence-absence data:

<center> If $y_{ij} \geq 1$, then, $y'_{ij} = 1$. </center>

Let us recall our `spe` data set:

```{r}
spe[1:6, 1:6]
``` 

Let us transform `spe` abundances to presence-absences:

```{r}
spe.pa <- decostand(spe, method = "pa")
spe.pa[1:6, 1:6]
```

## Species profiles transformation

Sometimes, one wants to remove the effects of highly abundant units. We can transform the data into profiles of relative species abundances through the following equation:

$$y'_{ij} = \frac{y_{ij}}{y_{i+}}$$

where, $yi+$ indicates the sample total count over all $j=1,…,m$ species, for the $i$-th sample.

In `decostand()`, we can use the `method` with `"total"`:

```{r}
spe.total <- decostand(spe, 
                       method = "total")
spe.total[1:5, 1:6]
```

## Hellinger transformation

We can take the square-root of the _species profile transformation_ and obtain the _Hellinger transformation_, which has very good mathematical properties and allows us to reduce the effects of $y_{ij}$ values that are extremely large.

$$y'_{ij} = \sqrt{\frac{y_{ij}}{y_{i+}}}$$

In `decostand()`, we can use the `method` with `"hellinger"`:

```{r}
spe.total <- decostand(spe, 
                       method = "hellinger")
spe.total[1:5, 1:6]
```

## Z-score standardization

Z-score standardization, also known as standard score normalization, is a technique used to transform a distribution of data to a standard normal distribution with a mean of 0 and a standard deviation of 1. 
It involves subtracting the mean of the data and dividing by the standard deviation.

Standardizing environmental variables is crucial as you cannot compare the effects of variables with different units:

```{r, eval = -1}
?decostand
env.z <- decostand(env, method = "standardize")
```

This centres and scales the variables to make your downstream analysis more appropriate:

```{r}
apply(env.z, 2, mean)
apply(env.z, 2, sd)
```

We will see more details about this transformation in the next sections!

#### Little review

:::: explanation 
**Association -** "general term to describe any measure or coefficient
to quantify the resemblance or difference between objects or
descriptors. In an analysis between descriptors, zero means no
association." (Legendre and Legendre 2012).

**Similarity -** a measure that is "maximum (S=1) when two objects are
identical and minimum when two objects are completely different."
(Legendre and Legendre 2012).

**Distance (also called dissimilarity) -** a measure that is "maximum
(D=1) when two objects are completely different". (Legendre and Legendre
2012). Distance or dissimilarity (D) = 1-S
::::

Choosing an association measure depends on your data, but also on what
you know, ecologically about your data. 

Here are some commonly used dissimilarity (distance) measures (recreated
from Gotelli and Ellison 2004):

  Measure name   Property      Description
  -------------- ------------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Euclidean      Metric        Distance between two points in 2D space.
  Manhattan      Metric        Distance between two points, where the distance is the sum of differences of their Cartesian coordinates, i.e. if you were to make a right able between the points.
  Chord          Metric        This distance is generally used to assess differences due to genetic drift.
  Mahalanobis    Metric        Distance between a point and a set distribution, where the distance is the number of standard deviations of the point from the mean of the distribution.
  Chi-square     Metric        Similar to Euclidean.
  Bray-Curtis    Semi-metric   Dissimilarity between two samples (or sites) where the sum of lower values for species present in both samples are divided by the sum of the species counted in each sample.
  Jaccard        Metric        [Description](http://en.wikipedia.org/wiki/Jaccard_index)
  Sorensen\'s    Semi-metric   Bray-Curtis is 1 - Sorensen

#### Extra: environmental data set

**Quantitative environmental data** Let's look at *associations* between
environmental variables (also known as Q mode):

```{r, echo = TRUE, eval = FALSE}
?dist # this function also compute dissimilarity matrix
env.de<-dist(env.z, method = "euclidean") # euclidean distance matrix of the standardized environmental variables 
windows() #Creates a separate graphical window
coldiss(env.de, diag=TRUE)
```

We can then look at the *dependence* between environmental variables
(also known as R mode):

```{r, echo = TRUE, eval = FALSE}
(env.pearson<-cor(env)) # Pearson r linear correlation
round(env.pearson, 2) #Rounds the coefficients to 2 decimal points 
(env.ken<-cor(env, method="kendall")) # Kendall tau rank correlation
round(env.ken, 2) 
```

The Pearson correlation measures the linear correlation between two
variables. The Kendall tau is a rank correlation which means that it
quantifies the relationship between two descriptors or variables when
the data are ordered within each variable.

In some cases, there may be mixed types of environmental variables. Q
mode can still be used to find associations between these environmental
variables. We'll do this by first creating an example dataframe:

```{r, echo = TRUE, eval = FALSE}
var.g1<-rnorm(30, 0, 1)
var.g2<-runif(30, 0, 5)
var.g3<-gl(3, 10)
var.g4<-gl(2, 5, 30)
(dat2<-data.frame(var.g1, var.g2, var.g3, var.g4))
str(dat2)
summary(dat2)
```

A dissimilarity matrix can be generated for these mixed variables using
the Gower dissimilarity matrix:

```{r, echo = TRUE, eval = FALSE}
?daisy #This function can handle NAs in the data
(dat2.dg<-daisy(dat2, metric="gower"))
coldiss(dat2.dg)
```

**Challenge 1 - Advanced** Calculate the Bray-Curtis and the Gower
dissimilarity of species abundance CHA, TRU and VAI for sites 1, 2 and 3
(using the "spe" and "env" dataframes) *without using the decostand()
function.*

**Challenge 1 - Advanced Solution** \<hidden\>

Subset the species data so that only sites 1, 2 are included and
only the species CHA, TRU and VAI.

```{r, echo = TRUE, eval = FALSE}
spe.challenge<-spe[1:3,1:3] #”[1:3,” refers to rows 1 to 3 while “,1:3]” refers to the first 3 species columns (in #this case the three variables of interest)
```

Determine total species abundance for each site of interest (sum of the
3 rows). This will be for the denominator in the above equation.

```{r, echo = TRUE, eval = FALSE}
(Abund.s1<-sum(spe.challenge[1,]))
(Abund.s2<-sum(spe.challenge[2,]))
(Abund.s3<-sum(spe.challenge[3,]))
#() around code will cause output to print right away in console
```

Now calculate the difference in species abundances for each pair of
sites. For example, what is the difference between the abundance of CHA
and TRU in site 1? You need to calculate the following differences: CHA
and TRU site 1 CHA and VAI site 1 TRU and VAI site 1 CHA and TRU site 2
CHA and VAI site 2 TRU and VAI site 2 CHA and TRU site 3 CHA and VAI
site 3 TRU and VAI site 3

```{r, echo = TRUE, eval = FALSE}
Spec.s1s2<-0
Spec.s1s3<-0
Spec.s2s3<-0
for (i in 1:3) {
  Spec.s1s2<-Spec.s1s2+abs(sum(spe.challenge[1,i]-spe.challenge[2,i]))
  Spec.s1s3<-Spec.s1s3+abs(sum(spe.challenge[1,i]-spe.challenge[3,i]))
  Spec.s2s3<-Spec.s2s3+abs(sum(spe.challenge[2,i]-spe.challenge[3,i])) }
```

Now take the differences you have calculated as the numerator in the
equation for Bray-Curtis dissimilarity and the total species abundance
that you already calculated as the denominator.

```{r, echo = TRUE, eval = FALSE}
(db.s1s2<-Spec.s1s2/(Abund.s1+Abund.s2)) #Site 1 compared to site 2
(db.s1s3<-Spec.s1s3/(Abund.s1+Abund.s3)) #Site 1 compared to site 3
(db.s2s3<-Spec.s2s3/(Abund.s2+Abund.s3)) #Site 2 compared to site 3 
```

You should find values of 0.5 for site 1 to site 2, 0.538 for site 1 to
site 3 and 0.053 for site 2 to 3.

Check your manual results with what you would find using the function
vegdist() with the Bray-Curtis method:

```{r, echo = TRUE, eval = FALSE}
(spe.db.challenge<-vegdist(spe.challenge, method="bray"))
```

A matrix looking like this is produced, which should be the same as your
manual calculations:

           Site 1   Site 2
  -------- -------- --------
  Site 2   0.5      \--
  Site 3   0.538    0.0526

For the Gower dissimilarity, proceed in the same way but use the
appropriate equation: 

```{r, echo = TRUE, eval = FALSE}
# Calculate the number of columns in your dataset
M<-ncol(spe.challenge)

# Calculate the species abundance differences between pairs of sites for each species
Spe1.s1s2<-abs(spe.challenge[1,1]-spe.challenge[2,1])
Spe2.s1s2<-abs(spe.challenge[1,2]-spe.challenge[2,2])
Spe3.s1s2<-abs(spe.challenge[1,3]-spe.challenge[2,3])
Spe1.s1s3<-abs(spe.challenge[1,1]-spe.challenge[3,1])
Spe2.s1s3<-abs(spe.challenge[1,2]-spe.challenge[3,2])
Spe3.s1s3<-abs(spe.challenge[1,3]-spe.challenge[3,3])
Spe1.s2s3<-abs(spe.challenge[2,1]-spe.challenge[3,1])
Spe2.s2s3<-abs(spe.challenge[2,2]-spe.challenge[3,2])
Spe3.s2s3<-abs(spe.challenge[2,3]-spe.challenge[3,3])

# Calculate the range of each species abundance between sites  
Range.spe1<-max(spe.challenge[,1]) - min (spe.challenge[,1])
Range.spe2<-max(spe.challenge[,2]) - min (spe.challenge[,2])
Range.spe3<-max(spe.challenge[,3]) - min (spe.challenge[,3])

# Calculate the Gower dissimilarity  
(dg.s1s2<-(1/M)*((Spe2.s1s2/Range.spe2)+(Spe3.s1s2/Range.spe3)))
(dg.s1s3<-(1/M)*((Spe2.s1s3/Range.spe2)+(Spe3.s1s3/Range.spe3)))
(dg.s2s3<-(1/M)*((Spe2.s2s3/Range.spe2)+(Spe3.s2s3/Range.spe3)))

# Compare your results
(spe.db.challenge<-vegdist(spe.challenge, method="gower"))
```

# (PART\*) Clustering {-}

# Clustering

One application of association matrices is clustering.
Clustering highlights structures in the data by partitioning either the objects or the descriptors.
As a result, similar objects are combined into groups, allowing distinctions -- or contrasts -- between groups to be identified. 
One goal of ecologists could be to divide a set of sitesinto groups with respect to their environmental conditions or their community composition.

Clustering results are often represented as _dendrograms_ (trees), where
objects agglomerate into groups. 
There are several families of clustering methods, but for the purpose of this workshop, we will
present an overview of three hierarchical agglomerative clustering
methods: single linkage, complete linkage, and Ward's minimum variance
clustering. _See Chapter 8 of Legendre and Legendre 2012 for more details
on the different families of clustering methods._

In hierarchical methods, elements of lower clusters (or groups) become
members of larger, higher ranking clusters, e.g. species, genus, family,
order. Prior to clustering, one needs to create an association matrix
among the objects. Distance matrix is the default choice of clustering
functions in R. The association matrix is first sorted in increasing
distance order (or decreasing similarities). Then, groups are formed
hierarchically following rules specific to each method.

```{r, fig.width=10, echo = FALSE}
# Demonstration of a cluster dendrogram
spe.hel<-decostand(spe, method="hellinger")
spe.dhel <- vegdist(spe.hel,method="euclidean")
spe.dhel.ward <- hclust(spe.dhel, method="ward.D2")
spe.dhel.ward$height<-sqrt(spe.dhel.ward$height)
plot(spe.dhel.ward, hang=-1) # hang=-1 aligns all objets on the same line

```

## Single linkage agglomerative clustering

Let\'s take a simple example of a euclidean distance matrix between 5
objets which were sorted in ascending order.

![](/cluster.example.png){.align-center}

In single linkage agglomerative clustering (also called nearest
neighbour sorting), the objects at the closest distances agglomerate.
The two closest objects agglomerate first, the next two closest
objects/clusters are then linked, and so on, which often generates long
thin clusters or chains of objects (see how objets 1 to 5 cluster
successively). Conversely, in complete linkage agglomerative clustering,
an object agglomerates to a group only when linked to the furthest
element of the group, which in turn links it to all members of that
group (in the above example, the group formed of objets 3 and 4 only
clusters with group 1-2 at 0.4, a distance at which objets 1, 2, 3 and 4
are all linked). As a result, complete linkage clustering will form many
small separate groups, and is more appropriate to look for contrasts,
discontinuities in the data.

## Complete linkage agglomerative clustering

Let's compare the single and complete linkage clustering methods using
the Doubs fish species data.

Species data were already Hellinger-transformed. The cluster analysis
requiring similarity or dissimilarity indices, the first step will be to
generate the Hellinger distance indices.

```{r, echo = TRUE, eval = FALSE}
spe.dhel<-vegdist(spe.hel,method="euclidean") #generates the distance matrix from Hellinger transformed data

#See difference between the two matrices
head(spe.hel)# Hellinger-transformed species data
head(spe.dhel)# Hellinger distances among sites
```

Most clustering methods can be computed with the function hclust() of
the stats package.

```{r, echo = TRUE, eval = FALSE}
#Faire le groupement à liens simples
#Perform single linkage clustering
spe.dhel.single<-hclust(spe.dhel, method="single")
plot(spe.dhel.single)

#Perform complete linkage clustering
spe.dhel.complete<-hclust(spe.dhel, method="complete")
plot(spe.dhel.complete)
```

![](/clust_single.png){.align-center}![](/clust_complete.png){.align-center}

Are there big differences between the two dendrograms?

In single linkage clustering, chains of objets occur (e.g. 19, 29, 30,
20, 26, etc.), whereas more contrasted groups are formed in the complete
linkage clustering.

## Ward's minimum variance clustering

Ward's minimum variance clustering differ from these two methods in that
it clusters objects into groups using the criterion of least squares
(similar to linear models). At the beginning, each object is considered
being a cluster of its own. At each step, the pair of clusters merging
is the one leading to minimum increase in total within-group sum of
squares.

Again, it is possible to generate a Ward's minimum variance clustering
with hclust(). However, the dendogram shows squared distances by
default. In order to compare this dendrogram to the single and complete
linkage clustering results, one must calculate the square root of the
distances.

```{r, echo = TRUE, eval = FALSE}
#Perform Ward minimum variance clustering
spe.dhel.ward<-hclust(spe.dhel, method="ward.D2")
plot(spe.dhel.ward)

#Re-plot the dendrogram by using the square roots of the fusion levels
spe.dhel.ward$height<-sqrt(spe.dhel.ward$height)
plot(spe.dhel.ward)
plot(spe.dhel.ward, hang=-1) # hang=-1 aligns all objets on the same line
```

![](/clust_ward.png){.align-center}
![](/clust_wardfinal.png){.align-center}

The clusters generated using Ward's method tend to be more spherical and
to contain similar numbers of objects.

One must be careful in the choice of an association measure and
clustering method in order to correctly address a problem. What are you
most interested in: gradients? Contrasts? In addition, the results
should be interpreted with respect to the properties of the method used.
If more than one method seems suitable to an ecological question,
computing them all and compare the results would be the way to go. As a
reminder, clustering is not a statistical method, but further steps can
be taken to identify interpretable clusters (e.g. where to cut the
tree), or to compute clustering statistics. Clustering can also be
combined to ordination in order to distinguish groups of sites. These go
beyond the scope of this workshop, but see Borcard et al. 2011 for more
details.

<!--chapter:end:04-association-distances.Rmd-->

# (PART\*) Unconstrained Ordination {-}

# What does "unconstrained" mean?

Unconstrained ordination allows us to organize samples, sites or species
along continuous gradients (e.g. ecological or environmental). The key
difference between unconstrained and constrained ordination (discussed
later in this workshop- see 'Canonical Ordination') is that in the
unconstrained techniques we are not attempting to define a relationship
between independent and dependent sets of variables.

Unconstrained ordination can be used to: 

- Assess relationships *within*
a set of variables (not between sets). 
- Find key components of
variation between samples, sites, species etc. 
- Reduce the number
dimensions in multivariate data without substantial loss of information.
- Create new variables for use in subsequent analyses (such as
regression). These principal components are weighted, linear
combinations of the original variables in the ordination.

[Source](http://www.umass.edu/landeco/teaching/multivariate/schedule/ordination1.pdf)

<!--chapter:end:05-unconstrained-ordination.Rmd-->


# Principal Component Analysis

Placeholder



<!--chapter:end:06-principal-component-analysis.Rmd-->


# Correspondence Analysis

Placeholder



<!--chapter:end:07-correspondence-analysis.Rmd-->


# Principal Coordinates Analysis

Placeholder



<!--chapter:end:08-principal-coordinate-analysis.Rmd-->


# Nonmetric MultiDimensional Scaling

Placeholder



<!--chapter:end:09-non-metric-multidimensional-scaling.Rmd-->

# (PART\*) Final considerations {-}

# Summary

Ordination is a powerful statistical tecnhique for studying the
relationships of objects characterized by several descriptors (e.g.
sites described by biotic communities, or environmental variables), but
serveral ordination methods exist. These methods mainly differ in the
type of distance preserved, the type of variables allowed and the
dimensions of the ordination space. To better guide your choice of the
ordination method to use, the following table identify the main
characteristics of the four ordination methods presented :

![](/summary_ordination.jpg){.align-center}

In the next workshop, you will see how to identify the relationships
between biotic communities and sets of environmental variables
describing the same sites, using canonical analyses.

# Additional resources

<!--chapter:end:10-final-considerations.Rmd-->

`r if (knitr::is_html_output()) '
# References
'`

<!--chapter:end:11-references.Rmd-->

