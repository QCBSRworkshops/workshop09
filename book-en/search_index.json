[["index.html", "Workshop 9: Multivariate Analyses in R QCBS R Workshop Series Preface 0.1 Code of conduct 0.2 Contributors 0.3 Contributing", " Workshop 9: Multivariate Analyses in R QCBS R Workshop Series Developed and maintained by the contributors of the QCBS R Workshop Series1 2023-01-13 17:08:11 Preface The QCBS R Workshop Series is a series of 10 workshops that walks participants through the steps required to use R for a wide array of statistical analyses relevant to research in biology and ecology. These open-access workshops were created by members of the QCBS both for members of the QCBS and the larger community. The content of this workshop has been peer-reviewed by several QCBS members. If you would like to suggest modifications, please contact the current series coordinators, listed on the main Github page. 0.1 Code of conduct The QCBS R Workshop Series and the QCBS R Symposium are venues dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. Participants, presenters and organizers of the workshop series and other related activities accept this Code of Conduct when being present at any workshop-related activities. We do not tolerate behaviour that is disrespectful or that excludes, intimidates, or causes discomfort to others. We do not tolerate discrimination or harassment based on characteristics that include, but are not limited to, gender identity and expression, sexual orientation, disability, physical appearance, body size, citizenship, nationality, ethnic or social origin, pregnancy, familial status, genetic information, religion or belief (or lack thereof), membership of a national minority, property, age, education, socio-economic status, technical choices, and experience level. It applies to all spaces managed by or affiliated with the workshop, including, but not limited to, workshops, email lists, and online forums such as GitHub, Slack and Twitter. 0.1.1 Expected behaviour All participants are expected to show respect and courtesy to others. All interactions should be professional regardless of platform: either online or in-person. In order to foster a positive and professional learning environment we encourage the following kinds of behaviours in all workshop events and platforms: Use welcoming and inclusive language Be respectful of different viewpoints and experiences Gracefully accept constructive criticism Focus on what is best for the community Show courtesy and respect towards other community members 0.1.2 Unacceptable behaviour Examples of unacceptable behaviour by participants at any workshop event/platform include: written or verbal comments which have the effect of excluding people on the - basis of membership of any specific group; causing someone to fear for their safety, such as through stalking or intimidation; violent threats or language directed against another person; the display of sexual or violent images; unwelcome sexual attention; nonconsensual or unwelcome physical contact; insults or put-downs; sexist, racist, homophobic, transphobic, ableist, or exclusionary jokes; incitement to violence, suicide, or self-harm; continuing to initiate interaction (including photography or recording) with - someone after being asked to stop; publication of private communication without consent. 0.2 Contributors Originally developed by: Contributed with changes to the presentation: Contributed with changes to the written material: Contributed by reporting issues and suggesting modifications: 0.3 Contributing Under construction. The QCBS R Workshop Series is part of the Québec Centre for Biodiversity Science, and is maintained by the series coordinators and graduent student, postdoctoral, and research professional members. The contributors for this workshop can be accessed here.↩︎ "],["learning-objectives.html", "Chapter 1 Learning objectives", " Chapter 1 Learning objectives Learn the basics of multivariate analysis to reveal patterns in community composition data Use R to perform an unconstrained ordination Learn about similarity and dissimilarity coefficients and transformations to perform multivariate analysis Use R to create dendrograms Learn the following methods: Clustering analysis Principal Component Analysis (PCA) Principal Coordinate Analysis (PCoA) Non-Metric MultiDimensional Scaling (NMDS) "],["preparing-for-the-workshop.html", "Chapter 2 Preparing for the workshop", " Chapter 2 Preparing for the workshop To prepare for this workshop, you must do the following steps: Download the data required for this workshop: DoubsEnv data DoubsSpe data Their data can also be retrieved from the ade4 package: library(ade4) data(doubs) spe &lt;- doubs$fish env &lt;- doubs$env Alternatively, from the codep package: library(codep) data(Doubs) spe &lt;- Doubs.fish env &lt;- Doubs.env Download the RScript containing the coldiss() function: R Script Coldiss R function You must also use these packages: * ape * ade4 * codep * gclus * vegan * GGally * PlaneGeometry * remotes list.of.packages &lt;- c(&quot;ape&quot;, &quot;ade4&quot;, &quot;codep&quot;, &quot;gclus&quot;, &quot;vegan&quot;, &quot;GGally&quot;, &quot;PlaneGeometry&quot;, &quot;remotes&quot;, &quot;matlib&quot;) new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[, &quot;Package&quot;])] if (length(new.packages) &gt; 0) { install.packages(new.packages, dependencies = TRUE) print(paste0(&quot;The following package was installed:&quot;, new.packages)) } else if (length(new.packages) == 0) { print(&quot;All packages were already installed previously&quot;) } ## Installing packages into &#39;/home/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;bit&#39;, &#39;bit64&#39;, &#39;rbibutils&#39;, &#39;XML&#39;, &#39;uuid&#39;, &#39;segmented&#39;, &#39;clipr&#39;, &#39;vroom&#39;, &#39;tzdb&#39;, &#39;gmp&#39;, &#39;polynom&#39;, &#39;Rdpack&#39;, &#39;AsioHeaders&#39;, &#39;png&#39;, &#39;jpeg&#39;, &#39;interp&#39;, &#39;rncl&#39;, &#39;RNeXML&#39;, &#39;seqinr&#39;, &#39;reshape2&#39;, &#39;classInt&#39;, &#39;DBI&#39;, &#39;wk&#39;, &#39;proxy&#39;, &#39;colorspace&#39;, &#39;DEoptimR&#39;, &#39;checkmate&#39;, &#39;readr&#39;, &#39;coda&#39;, &#39;partitions&#39;, &#39;mathjaxr&#39;, &#39;disordR&#39;, &#39;SparseM&#39;, &#39;MatrixModels&#39;, &#39;minqa&#39;, &#39;nloptr&#39;, &#39;websocket&#39;, &#39;fastmatch&#39;, &#39;generics&#39;, &#39;quadprog&#39;, &#39;latticeExtra&#39;, &#39;phylobase&#39;, &#39;adegenet&#39;, &#39;spData&#39;, &#39;sf&#39;, &#39;units&#39;, &#39;s2&#39;, &#39;e1071&#39;, &#39;hms&#39;, &#39;prettyunits&#39;, &#39;isoband&#39;, &#39;tidyselect&#39;, &#39;farver&#39;, &#39;labeling&#39;, &#39;munsell&#39;, &#39;purrr&#39;, &#39;cpp11&#39;, &#39;backports&#39;, &#39;pcaPP&#39;, &#39;robustbase&#39;, &#39;som&#39;, &#39;lars&#39;, &#39;pls&#39;, &#39;mclust&#39;, &#39;tweenr&#39;, &#39;polyclip&#39;, &#39;systemfonts&#39;, &#39;RcppEigen&#39;, &#39;Formula&#39;, &#39;gridExtra&#39;, &#39;data.table&#39;, &#39;htmlTable&#39;, &#39;viridis&#39;, &#39;haven&#39;, &#39;statnet.common&#39;, &#39;rJava&#39;, &#39;lazyeval&#39;, &#39;hunspell&#39;, &#39;estimability&#39;, &#39;numDeriv&#39;, &#39;mvtnorm&#39;, &#39;pgnorm&#39;, &#39;pracma&#39;, &#39;magic&#39;, &#39;freealg&#39;, &#39;rex&#39;, &#39;httr&#39;, &#39;abind&#39;, &#39;pbkrtest&#39;, &#39;quantreg&#39;, &#39;lme4&#39;, &#39;chromote&#39;, &#39;gee&#39;, &#39;expm&#39;, &#39;igraph&#39;, &#39;phangorn&#39;, &#39;pixmap&#39;, &#39;sp&#39;, &#39;ade4TkGUI&#39;, &#39;adegraphics&#39;, &#39;adephylo&#39;, &#39;CircStats&#39;, &#39;deldir&#39;, &#39;spdep&#39;, &#39;splancs&#39;, &#39;waveslim&#39;, &#39;progress&#39;, &#39;foreach&#39;, &#39;doParallel&#39;, &#39;iterators&#39;, &#39;permute&#39;, &#39;markdown&#39;, &#39;ggplot2&#39;, &#39;dplyr&#39;, &#39;forcats&#39;, &#39;gtable&#39;, &#39;plyr&#39;, &#39;RColorBrewer&#39;, &#39;reshape&#39;, &#39;scales&#39;, &#39;tidyr&#39;, &#39;broom&#39;, &#39;broom.helpers&#39;, &#39;chemometrics&#39;, &#39;geosphere&#39;, &#39;ggforce&#39;, &#39;Hmisc&#39;, &#39;intergraph&#39;, &#39;labelled&#39;, &#39;maps&#39;, &#39;mapproj&#39;, &#39;network&#39;, &#39;scagnostics&#39;, &#39;sna&#39;, &#39;roxygen2&#39;, &#39;crosstalk&#39;, &#39;spelling&#39;, &#39;emmeans&#39;, &#39;gsl&#39;, &#39;uniformly&#39;, &#39;sdpt3r&#39;, &#39;fitConic&#39;, &#39;viridisLite&#39;, &#39;sets&#39;, &#39;ellipse&#39;, &#39;freegroup&#39;, &#39;elliptic&#39;, &#39;rgl&#39;, &#39;brew&#39;, &#39;curl&#39;, &#39;covr&#39;, &#39;git2r&#39;, &#39;mockery&#39;, &#39;pkgbuild&#39;, &#39;pingr&#39;, &#39;webfakes&#39;, &#39;car&#39;, &#39;carData&#39;, &#39;webshot2&#39; ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;units&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;rJava&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;curl&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;httr&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;scagnostics&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;chromote&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;covr&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;RNeXML&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;sf&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;webshot2&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;phylobase&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;spdep&#39; had non-zero exit status ## Warning in install.packages(new.packages, dependencies = TRUE): installation of ## package &#39;adephylo&#39; had non-zero exit status ## [1] &quot;The following package was installed:ape&quot; ## [2] &quot;The following package was installed:ade4&quot; ## [3] &quot;The following package was installed:codep&quot; ## [4] &quot;The following package was installed:gclus&quot; ## [5] &quot;The following package was installed:vegan&quot; ## [6] &quot;The following package was installed:GGally&quot; ## [7] &quot;The following package was installed:PlaneGeometry&quot; ## [8] &quot;The following package was installed:remotes&quot; ## [9] &quot;The following package was installed:matlib&quot; # Load all required libraries at once lapply(list.of.packages, require, character.only = TRUE, quietly = TRUE) ## Registered S3 method overwritten by &#39;vegan&#39;: ## method from ## reorder.hclust gclus ## This is vegan 2.6-4 ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE ## ## [[4]] ## [1] TRUE ## ## [[5]] ## [1] TRUE ## ## [[6]] ## [1] TRUE ## ## [[7]] ## [1] TRUE ## ## [[8]] ## [1] TRUE ## ## [[9]] ## [1] TRUE # source(file.choose()) # use coldiss.R which you have # downloaded to your own directory "],["recap-univariate-analyses.html", "Chapter 3 Recap: Univariate analyses", " Chapter 3 Recap: Univariate analyses We have learned a multitude of analyses that allowed us to interpret ecological data while depicting the effects of one or multiple variables in one response variable. We can recall the: General Linear Models, from which we used the functions: lm(); anova(); t.test(); lmer(). Generalized Linear Models, where we learned how to apply using: glm() and glmer() with several family() link functions. Generalized Additive Models, with the: gam() function. These models allowed us to ask questions such as: What are the effects of precipitation and temperature on species richness? How does the abundance of microbes change between hosts? Do co-occurring fish become more aggressive after being induced to fear? However, one may be interested in making inferences from ecological data containing more than one outcome or dependent variable. This interest may be driven by hypothesis testing and modelling, but also be entirely exploratory. "],["intro-multivariate-analyses.html", "Chapter 4 Intro: Multivariate analyses", " Chapter 4 Intro: Multivariate analyses For instance, our research question might be: How does the bacterial composition on maple leaves changes along the elevational gradient? What is the compositional dissimilarity of the bat communities? How closely-related spider local communities are in relation to their composition? In all these cases, the outcome is composed of several variables, e.g. usually a sample-by-species or sample-by-environment matrix. "],["setting-up-our-goals.html", "Chapter 5 Setting up our goals", " Chapter 5 Setting up our goals We will now dive into multivariate statistics, a tool set that will allow us to address questions requiring the simultaneous observation or analysis of more than one outcome variable. We will explore certain methods, such as: Association (or dis-similarity) measures and matrices; Classification (or cluster) analysis; Unconstrained ordination; Constrained (or canonical) ordination (in Workshop 10). Before everything, we will do a little review on matrix algebra. "],["matrix-algebra-very-briefly.html", "Chapter 6 Matrix algebra, very briefly 6.1 Data sets are matrices 6.2 Association matrices", " Chapter 6 Matrix algebra, very briefly Matrix algebra is well-suited for ecology, because most (if not all) data sets we work with are in a matrix format. 6.1 Data sets are matrices Ecological data tables are obtained as object-observations or sampling units, and are often recorded as this: Objects \\(y_1\\) \\(y_2\\) \\(\\dots\\) \\(y_n\\) \\(x_1\\) \\(y_{1,1}\\) \\(y_{1,2}\\) \\(\\dots\\) \\(y_{1,n}\\) \\(x_2\\) \\(y_{2,1}\\) \\(y_{2,2}\\) \\(\\dots\\) \\(y_{2,n}\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\ddots\\) \\(\\vdots\\) \\(x_m\\) \\(y_{m,1}\\) \\(y_{m,2}\\) \\(\\dots\\) \\(y_{m,n}\\) where \\(x_m\\) is the sampling unit \\(m\\); and \\(y_n\\) is the ecological descripor that can be, for example, species present in a sampling unit, locality, or a chemical variable. The same ecological data table can be represented in matrix notation like this: \\[Y = [y_{m,n}] = \\begin{bmatrix} y_{1,1} &amp; y_{1,2} &amp; \\cdots &amp; y_{1,n} \\\\ y_{2,1} &amp; y_{2,2} &amp; \\cdots &amp; y_{2,n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ y_{m,1} &amp; y_{m,2} &amp; \\cdots &amp; y_{m,n} \\end{bmatrix}\\] where lowercase letters indicate elements, and the subscript letters indicate the position of these elements in the matrix (and in the table!). Moreover, any subset of a matrix can be recognized. We can subset a row matrix, as below: \\[\\begin{bmatrix} y_{1,1} &amp; y_{1,2} &amp; \\cdots &amp; y_{1,n} \\\\ \\end{bmatrix}\\] We can also subset a column matrix, as below: \\[\\begin{bmatrix} y_{1,1} \\\\ y_{2,2} \\\\ \\vdots \\\\ y_{m,2} \\end{bmatrix}\\] 6.2 Association matrices Two important matrices can be derived from the ecological data matrix: the association matrix among objects and the association matrix among descriptors. Using the data from our matrix \\(Y\\), \\[ Y = \\begin{array}{cc} \\begin{array}{ccc} x_1 \\rightarrow\\\\ x_2 \\rightarrow\\\\ \\vdots \\\\ x_m \\rightarrow\\\\ \\end{array} &amp; \\begin{bmatrix} y_{1,1} &amp; y_{1,2} &amp; \\cdots &amp; y_{1,n} \\\\ y_{2,1} &amp; y_{2,2} &amp; \\cdots &amp; y_{2,n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ y_{m,1} &amp; y_{m,2} &amp; \\cdots &amp; y_{m,n} \\end{bmatrix} \\end{array} \\] one can examine the relationship between the first two objects: \\[x_1 \\rightarrow \\begin{bmatrix} y_{1,1} &amp; y_{1,2} &amp; \\cdots &amp; y_{1,n} \\\\ \\end{bmatrix} \\] \\[x_2 \\rightarrow \\begin{bmatrix} y_{2,1} &amp; y_{2,2} &amp; \\cdots &amp; y_{2,n} \\\\ \\end{bmatrix} \\] and obtain \\(a_{1,2}\\). We can populate the association matrix \\(A_{n,n}\\) with the relationships between all objects from \\(Y\\): \\[A_{n,n} = \\begin{bmatrix} a_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,n} \\\\ a_{2,1} &amp; a_{2,2} &amp; \\cdots &amp; a_{2,n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n,1} &amp; a_{n,2} &amp; \\cdots &amp; a_{n,n} \\end{bmatrix}\\] Because \\(A_{n,n}\\) has the same number of rows and columns, it is denoted a square matrix. Therefore, \\(A_{n,n}\\) has \\(n^2\\) elements. We can also obtain the relationship between the first two descriptors of \\(Y\\), \\(y_1\\) and \\(y_2\\): \\[\\begin{bmatrix} y_{1,2} \\\\ y_{2,2} \\\\ \\vdots \\\\ y_{m,2} \\end{bmatrix}\\] \\[\\begin{bmatrix} y_{1,1} \\\\ y_{2,1} \\\\ \\vdots \\\\ y_{m,1} \\end{bmatrix}\\] and store it in \\(a_{1,2}\\). We can populate the association matrix \\(A_{m,m}\\) with the relationships between all descriptors from \\(Y\\): \\[A_{m,m} = \\begin{bmatrix} a_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,m} \\\\ a_{2,1} &amp; a_{2,2} &amp; \\cdots &amp; a_{2,m} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m,1} &amp; a_{m,2} &amp; \\cdots &amp; a_{m,m} \\end{bmatrix}\\] This \\(A_{m,m}\\) is a square matrix, and it has \\(m^2\\) elements. These matrices, \\(A_{n,n}\\) and \\(A_{m,m}\\), are the basis of Q-mode and R-mode analyses in ecology. R-mode constitutes of analyzing the association between descriptors or species, while Q-mode analyzes the association between OTUs, objects or sites. "],["exploring-the-dataset.html", "Chapter 7 Exploring the dataset 7.1 Doubs river fish communities 7.2 Doubs river environmental data", " Chapter 7 Exploring the dataset We will use two main data sets in the first part of this workshop. They come from Verneaux’s PhD thesis (1973), where he proposed to use fish species to characterize ecological zones along European rivers and streams. He collected data at 30 localities along the Doubs river, which runs near the France-Switzerland border, in the Jura Mountains. He showed that fish communities were biological indicators of these water bodies. Their data is split in three matrices: The abundance of 27 fish species across the communities (DoubsSpe.csv and hereon, the spe object); The environmental variables recorded at each site (DoubsEnv.csv and hereon, the env object); and, The geographical coordinates of each site. Verneaux, J. (1973) Cours d’eau de Franche-Comté (Massif du Jura). Recherches écologiques sur le réseau hydrographique du Doubs. Essai de biotypologie. Thèse d’état, Besançon. 1–257. 7.1 Doubs river fish communities You can download these datasets from r.qcbs.ca/workshops/r-workshop-09. We can load their data from the data/ directory in this workshop: spe &lt;- read.csv(&quot;data/doubsspe.csv&quot;, row.names = 1) env &lt;- read.csv(&quot;data/doubsenv.csv&quot;, row.names = 1) Their data can also be retrieved from the ade4 package: library(ade4) data(doubs) spe &lt;- doubs$fish env &lt;- doubs$env Alternatively, from the codep package: library(codep) data(Doubs) spe &lt;- Doubs.fish env &lt;- Doubs.env We can then explore the objects containing our newly loaded data. Let us peek into the spe data: head(spe)[, 1:8] ## CHA TRU VAI LOC OMB BLA HOT TOX ## 1 0 3 0 0 0 0 0 0 ## 2 0 5 4 3 0 0 0 0 ## 3 0 5 5 5 0 0 0 0 ## 4 0 4 5 5 0 0 0 0 ## 5 0 2 3 2 0 0 0 0 ## 6 0 3 4 5 0 0 0 0 We can also use the str() function, which we learned in Workshops 1 and 2: str(spe) ## &#39;data.frame&#39;: 30 obs. of 27 variables: ## $ CHA: int 0 0 0 0 0 0 0 0 0 0 ... ## $ TRU: int 3 5 5 4 2 3 5 0 0 1 ... ## $ VAI: int 0 4 5 5 3 4 4 0 1 4 ... ## $ LOC: int 0 3 5 5 2 5 5 0 3 4 ... ## $ OMB: int 0 0 0 0 0 0 0 0 0 0 ... ## $ BLA: int 0 0 0 0 0 0 0 0 0 0 ... ## $ HOT: int 0 0 0 0 0 0 0 0 0 0 ... ## $ TOX: int 0 0 0 0 0 0 0 0 0 0 ... ## $ VAN: int 0 0 0 0 5 1 1 0 0 2 ... ## $ CHE: int 0 0 0 1 2 2 1 0 5 2 ... ## $ BAR: int 0 0 0 0 0 0 0 0 0 0 ... ## $ SPI: int 0 0 0 0 0 0 0 0 0 0 ... ## $ GOU: int 0 0 0 1 2 1 0 0 0 1 ... ## $ BRO: int 0 0 1 2 4 1 0 0 0 0 ... ## $ PER: int 0 0 0 2 4 1 0 0 0 0 ... ## $ BOU: int 0 0 0 0 0 0 0 0 0 0 ... ## $ PSO: int 0 0 0 0 0 0 0 0 0 0 ... ## $ ROT: int 0 0 0 0 2 0 0 0 0 0 ... ## $ CAR: int 0 0 0 0 0 0 0 0 0 0 ... ## $ TAN: int 0 0 0 1 3 2 0 0 1 0 ... ## $ BCO: int 0 0 0 0 0 0 0 0 0 0 ... ## $ PCH: int 0 0 0 0 0 0 0 0 0 0 ... ## $ GRE: int 0 0 0 0 0 0 0 0 0 0 ... ## $ GAR: int 0 0 0 0 5 1 0 0 4 0 ... ## $ BBO: int 0 0 0 0 0 0 0 0 0 0 ... ## $ ABL: int 0 0 0 0 0 0 0 0 0 0 ... ## $ ANG: int 0 0 0 0 0 0 0 0 0 0 ... You can also try some of these! # Try some of these! names(spe) # names of objects dim(spe) # dimensions str(spe) # structure of objects summary(spe) # summary statistics head(spe) # first 6 rows 7.2 Doubs river environmental data str(env) ## &#39;data.frame&#39;: 30 obs. of 11 variables: ## $ das: num 0.3 2.2 10.2 18.5 21.5 32.4 36.8 49.1 70.5 99 ... ## $ alt: int 934 932 914 854 849 846 841 792 752 617 ... ## $ pen: num 48 3 3.7 3.2 2.3 3.2 6.6 2.5 1.2 9.9 ... ## $ deb: num 0.84 1 1.8 2.53 2.64 2.86 4 1.3 4.8 10 ... ## $ pH : num 7.9 8 8.3 8 8.1 7.9 8.1 8.1 8 7.7 ... ## $ dur: int 45 40 52 72 84 60 88 94 90 82 ... ## $ pho: num 0.01 0.02 0.05 0.1 0.38 0.2 0.07 0.2 0.3 0.06 ... ## $ nit: num 0.2 0.2 0.22 0.21 0.52 0.15 0.15 0.41 0.82 0.75 ... ## $ amm: num 0 0.1 0.05 0 0.2 0 0 0.12 0.12 0.01 ... ## $ oxy: num 12.2 10.3 10.5 11 8 10.2 11.1 7 7.2 10 ... ## $ dbo: num 2.7 1.9 3.5 1.3 6.2 5.3 2.2 8.1 5.2 4.3 ... It contains the following variables: Variable Description das Distance from the source [km] alt Altitude [m a.s.l.] pen Slope [per thousand] deb Mean min. discharge [m3s-1] pH pH of water dur Ca conc. (hardness) [mgL-1] pho K conc. [mgL-1] nit N conc. [mgL-1] amn NH₄⁺ conc. [mgL-1] oxy Diss. oxygen [mgL-1] dbo Biol. oxygen demand [mgL-1] You can also use summary() to obtain summary statistics from the variables in env: summary(env) # summary statistics "],["dist.html", "Chapter 8 dist()", " Chapter 8 dist() Community resemblance is almost always assessed on the basis of species composition data in the form of a site-by-species data table \\(Y_{m,n}\\). We can obtain an association matrix \\(A_{m,m}\\) in the form of pairwise distances or dissimilarities \\(D_{m,m}\\) (or similarities \\(S_{m,m}\\)) and then analyse those distances. Association matrices between objects or among descriptors allow for calculations of similarity or distances between objects or descriptors (Legendre and Legendre 2012). In R, we can compute distance or dissimilarity matrices using stats::dist(). For simplicity, let us do this without specifying arguments: dist(spe) Run dist(spe) from your end, and you should observe that the output from `dist(spe) is a lower triangular matrix representing pairwise associations between the columns of your original matrix. Let us see what the commands below show us: class(dist(spe)) ## [1] &quot;dist&quot; str(dist(spe)) as.matrix(dist(spe)) dim(as.matrix(dist(spe))) ## [1] 30 30 "],["types-of-distance-coefficients.html", "Chapter 9 Types of distance coefficients 9.1 Metric distances 9.2 Semimetric distances 9.3 Nonmetric distances 9.4 Representation", " Chapter 9 Types of distance coefficients There are three groups of distance coefficients: metrics, semimetrics, and nonmetrics . 9.1 Metric distances The first group consists of metrics, and its coefficients satisfy the following properties: minimum 0: if species \\(a\\) is equal to species \\(b\\), then \\(D(a,b)=0\\); positiveness: if \\(a \\neq b\\), then \\(D(a,b) &gt; 0\\); symmetry: \\(D(a,b) = D(b,a)\\); triangle inequality: \\(D(a,b) + D(b,c) \\geq D(a,c)\\). The sum of two sides of a triangle drawn in the Euclidean space is equal or greater than the third side. We can spot all these properties below: as.matrix(dist(spe))[1:3, 1:3] ## 1 2 3 ## 1 0.000000 5.385165 7.416198 ## 2 5.385165 0.000000 2.449490 ## 3 7.416198 2.449490 0.000000 9.1.1 Euclidean distances The most common metric distance measure is the Euclidean distance. It is computed using the Pythagorean formula: \\[D_{1} (x_1,x_2) = \\sqrt{\\sum_{j=1}^p(y_{1j} - y_{2j})^2}\\] Using stats::dist(), we can compute it with: spe.D.Euclid &lt;- dist(x = spe, method = &quot;euclidean&quot;) And, we can test whether a distance is Euclidean using: is.euclid(spe.D.Euclid) ## [1] TRUE 9.1.2 Challenge #1 Your turn! Using the dist() function, compute the Euclidean distance matrix \\(D_{hmm}\\) for the species abundances by site matrix \\(Y_{hmm}\\) below: Sites \\(y_1\\) \\(y_2\\) \\(y_3\\) \\(s_1\\) 0 4 8 \\(s_2\\) 0 1 1 \\(s_3\\) 1 0 0 Y.hmm &lt;- data.frame(y1 = c(0, 0, 1), y2 = c(4, 1, 0), y3 = c(8, 1, 0)) After this, look into the numbers, think critically about them! Solution: You should have something similar to this: Y.hmm.DistEu &lt;- dist(x = Y.hmm, method = &quot;euclidean&quot;) as.matrix(Y.hmm.DistEu) ## 1 2 3 ## 1 0.000000 7.615773 9.000000 ## 2 7.615773 0.000000 1.732051 ## 3 9.000000 1.732051 0.000000 Now, look into the composition and the distances between sites \\(s_2\\) and \\(s_3\\) and between \\(s_1\\) and \\(s_2\\). What is going on? The Euclidean distance between sites \\(s_2\\) and \\(s_3\\), which have no species in common, is smaller than the distance between \\(s_1\\) and \\(s_2\\), which share species \\(y_2\\) and \\(y_3\\) (!). From an ecological perspective, this is a problematic assessment of the relationship among sites. This issue is known as the double-zero problem, i.e. double zeroes are treated in the same way as double presences, so that the double zeros shrink the distance between two sites. Euclidean distances ( \\(D_1\\) ) should thus not be used to compare sites based on species abundances. 9.1.3 Chord distances Orlóci (1967) proposed the Chord distance to analyse community composition. It consists of: 1. Normalizing the data, i.e. scaling site vectors to length 1 by dividing species abundances in a given sample by the square-rooted sum of square abundances in all samples as \\[y&#39;_{Uj}=y_{Uj}/\\sum^s_{j=1}{y^2_{Uj}}\\] 2. Calculating the Euclidean distances on this normalized data: \\[D_{3} (x_1,x_2) = \\sqrt{\\sum_{j=1}^p(y&#39;_{1j} - y&#39;_{2j})^2}\\] We can use vegan::vegdist() for this one: spe.D.Ch &lt;- vegdist(spe, method = &quot;chord&quot;) ## Warning in vegdist(spe, method = &quot;chord&quot;): you have empty rows: their dissimilarities may be ## meaningless in method &quot;chord&quot; ## Warning in vegdist(spe, method = &quot;chord&quot;): missing values in results as.matrix(spe.D.Ch)[1:3, 1:3] ## 1 2 3 ## 1 0.0000000 0.7653669 0.9235374 ## 2 0.7653669 0.0000000 0.2309609 ## 3 0.9235374 0.2309609 0.0000000 When two sites share the same species in the same proportions of the number of individuals the value of \\(D_3\\) is \\(0\\), and when no species are shared, its value is \\(\\sqrt{2}\\). What happens if we compute Chord distances in the same site-by-species matrix \\(Y_{hmm}\\)? Let us try the Chord distances in the same matrix we used for Challenge #1: Y.hmm.DistCh &lt;- vegdist(Y.hmm, method = &quot;chord&quot;) as.matrix(Y.hmm.DistCh) ## 1 2 3 ## 1 0.0000000 0.3203645 1.414214 ## 2 0.3203645 0.0000000 1.414214 ## 3 1.4142136 1.4142136 0.000000 Now, let us compare with what we obtained when we used Euclidean distances: as.matrix(Y.hmm.DistEu) ## 1 2 3 ## 1 0.000000 7.615773 9.000000 ## 2 7.615773 0.000000 1.732051 ## 3 9.000000 1.732051 0.000000 See again how our matrix looks: Y.hmm ## y1 y2 y3 ## 1 0 4 8 ## 2 0 1 1 ## 3 1 0 0 So, adding any number of double zeroes to a pair of sites does not change the value of \\(D_3\\). Hence, Chord distances can be used to compare sites described by species abundances! 9.1.4 Jaccard’s coefficient Another popular association coefficient is the Jaccard similarity coefficient (1900). It is only appropriate for binary data, and its distance coefficient is defined with the size of the intersection divided by the size of the union of the sample sets. \\[D_{7}(x_1,x_2) = 1 - \\frac{\\vert x_1 \\cap x_2 \\vert}{\\vert x_1 \\cup x_2 \\vert} = 1 - \\frac{\\vert x_1 \\cap x_2 \\vert}{\\vert x_1 \\vert + \\vert x_2 \\vert - \\vert x_1 \\cap x_2 \\vert} = 1-\\frac{a}{a+b+c}\\] where, \\(a\\) is the number of species shared between \\(x_1\\) and \\(x_2\\) that are coded \\(1\\); \\(b\\) is the number of occurrences where \\(x_1\\) and \\(x_2\\) are known to be different; \\(c\\) is the number of common absences between \\(x_1\\) and \\(x_2\\), i.e. both \\(0\\). For example, for sites \\(x_1\\) and \\(x_2\\): \\(x_1,x_2\\) \\(y_1\\) \\(y_2\\) \\(y_3\\) \\(y_4\\) \\(y_5\\) \\(x_1\\) 0 1 0 1 0 \\(x_2\\) 0 1 1 1 1 So, we can calculate \\(a\\), \\(b\\), and \\(c\\): - \\(a\\) = 1 + 1 = 2 \\(b\\) = 1 + 1 = 2 \\(c\\) = 1 And, then our distance coefficient: \\[D_{7}(x_1,x_2) = 1-\\frac{2}{2+2+1}= 0.6\\] In R, you can use use the vegan::vegdist() function to calculate the Jaccard’s coefficient: spe.D.Jac &lt;- vegdist(spe, method = &quot;jaccard&quot;, binary = TRUE) ## Warning in vegdist(spe, method = &quot;jaccard&quot;, binary = TRUE): you have empty rows: their dissimilarities may be ## meaningless in method &quot;jaccard&quot; 9.2 Semimetric distances The second group consists of semimetrics, and they violate the triangle inequality property: minimum 0: if species \\(a\\) is equal to species \\(b\\), then \\(D(a,b)=0\\); positiveness: if \\(a \\neq b\\), then \\(D(a,b) &gt; 0\\); symmetry: \\(D(a,b) = D(b,a)\\); triangle inequality: \\({D(a,b) + D(b,c) \\geq or &lt; D(a,c)}\\). The sum of two sides of a triangle drawn in the Euclidean space is not equal or greater than the third side. 9.2.1 Sørensen’s coefficient All parameters in Jaccard’s similarity coefficient have equal weights. \\[D_{7}(x_1,x_2)=1-\\frac{a}{a+b+c}\\] However, you may want to consider that a presence of a species is more informative than its absence. The distance corresponding to Sørensen’s similarity coefficient (1948) gives weight to double presences: \\[D_{13}(x_1,x_2)=1-\\frac{2a}{2a+b+c}=\\frac{b+c}{2a+b+c}\\] where, \\(a\\) is the number of species shared between \\(x_1\\) and \\(x_2\\) that are coded \\(1\\); \\(b\\) is the number of occurrences where \\(x_1\\) and \\(x_2\\) are known to be different; \\(c\\) is the number of common absences between \\(x_1\\) and \\(x_2\\), i.e. both \\(0\\). In R, you can also use use the vegan::vegdist() function to calculate the Sørensen’s coefficient: spe.D.Sor &lt;- vegdist(spe, method = &quot;bray&quot;, binary = TRUE) ## Warning in vegdist(spe, method = &quot;bray&quot;, binary = TRUE): you have empty rows: their dissimilarities may be ## meaningless in method &quot;bray&quot; Because both Jaccard’s and Sørensen’s are only appropriate for presence-absence data, you must binary-transform abundance data using binary = TRUE in vegdist(). 9.2.2 Bray-Curtis’ coefficient The Bray-Curtis dissimilarity coefficient is a modified version of the Sørensen’s index and allows for species abundances: \\[D_{14}(x_1,x_2)=\\frac{\\sum{\\vert y_{1j}-y_{2j}\\vert}}{\\sum{( y_{1j}+y_{2j})}}=\\] \\[D_{14}(x_1,x_2)=1 - \\frac{2W}{A+B}\\] where, \\(W\\) is the sum of the lowest abundances in each species found between sites \\(x_1\\) and \\(x_2\\); \\(A\\) is the sum of all abundances in \\(x_1\\); and, \\(B\\) is the sum of all abundances in \\(x_2\\). For example, for sites \\(x_1\\) and \\(x_2\\): \\(x_1,x_2\\) \\(y_1\\) \\(y_2\\) \\(y_3\\) \\(y_4\\) \\(y_5\\) \\(x_1\\) 2 1 0 5 2 \\(x_2\\) 5 1 3 1 1 So: - \\(W = 2 + 1 + 0 + 1 + 1 = 5\\) \\(A = 2 + 1 + 0 + 5 + 0 = 8\\) \\(B = 5 + 1 + 3 + 1 + 2 = 12\\) \\[D_{14}(x_1,x_2) = 1-\\frac{2 \\times 5}{8+12} = 0.5\\] To calculate the Bray-Curtis dissimilarity coefficient, which can account for abundances, you need to set binary = FALSE. spe.db.pa &lt;- vegdist(spe, method = &quot;bray&quot;, binary = FALSE) ## Warning in vegdist(spe, method = &quot;bray&quot;, binary = FALSE): you have empty rows: their dissimilarities may be ## meaningless in method &quot;bray&quot; spe.db &lt;- as.matrix(spe.db.pa) 9.3 Nonmetric distances minimum 0: if species \\(a\\) is equal to species \\(b\\), then \\(D(a,b)=0\\); positiveness: if \\(a \\neq b\\), then \\(D(a,b) &gt; or &lt; 0\\); symmetry: \\(D(a,b) = D(b,a)\\); triangle inequality: \\({D(a,b) + D(b,c) \\geq or &lt; D(a,c)}\\). The sum of two sides of a triangle drawn in the Euclidean space is not equal or greater than the third side. 9.4 Representation We can create graphical depictions of association matrices using the coldiss() function: coldiss(spe.D.Jac) "],["transformations.html", "Chapter 10 Transformations 10.1 Presence-absence transformation 10.2 Species profiles transformation 10.3 Hellinger transformation 10.4 Z-score standardization", " Chapter 10 Transformations Communities sampled over homogeneous or short environmental conditions can have species compositions with few zeroes, so that Euclidean distances could be enough to characterize them. Nevertheless, this is rarely the reality. Species may be highly frequent when conditions are favourable, or may be absent from many sites. Sometimes, this skewness may introduce spurious problems to our analyses. We may then have to transform our composition data to appropriately analyze it. In R, we can rely on vegan::decostand() for many types of transformations. Take a look into the help of this function to see the available options: ?decostand() 10.1 Presence-absence transformation We can change the argument method to \"pa\" in vegdist() to transform our abundance data into presence-absence data: If \\(y_{ij} \\geq 1\\), then, \\(y&#39;_{ij} = 1\\). Let us recall our spe data set: spe[1:6, 1:6] ## CHA TRU VAI LOC OMB BLA ## 1 0 3 0 0 0 0 ## 2 0 5 4 3 0 0 ## 3 0 5 5 5 0 0 ## 4 0 4 5 5 0 0 ## 5 0 2 3 2 0 0 ## 6 0 3 4 5 0 0 Let us transform spe abundances to presence-absences: spe.pa &lt;- decostand(spe, method = &quot;pa&quot;) spe.pa[1:6, 1:6] ## CHA TRU VAI LOC OMB BLA ## 1 0 1 0 0 0 0 ## 2 0 1 1 1 0 0 ## 3 0 1 1 1 0 0 ## 4 0 1 1 1 0 0 ## 5 0 1 1 1 0 0 ## 6 0 1 1 1 0 0 10.2 Species profiles transformation Sometimes, one wants to remove the effects of highly abundant units. We can transform the data into profiles of relative species abundances through the following equation: \\[y&#39;_{ij} = \\frac{y_{ij}}{y_{i+}}\\] where, \\(yi+\\) indicates the sample total count over all \\(j=1,…,m\\) species, for the \\(i\\)-th sample. In decostand(), we can use the method with \"total\": spe.total &lt;- decostand(spe, method = &quot;total&quot;) spe.total[1:5, 1:6] ## CHA TRU VAI LOC OMB BLA ## 1 0 1.00000000 0.00000000 0.00000000 0 0 ## 2 0 0.41666667 0.33333333 0.25000000 0 0 ## 3 0 0.31250000 0.31250000 0.31250000 0 0 ## 4 0 0.19047619 0.23809524 0.23809524 0 0 ## 5 0 0.05882353 0.08823529 0.05882353 0 0 10.3 Hellinger transformation We can take the square-root of the species profile transformation and obtain the Hellinger transformation, which has very good mathematical properties and allows us to reduce the effects of \\(y_{ij}\\) values that are extremely large. \\[y&#39;_{ij} = \\sqrt{\\frac{y_{ij}}{y_{i+}}}\\] In decostand(), we can use the method with \"hellinger\": spe.total &lt;- decostand(spe, method = &quot;hellinger&quot;) spe.total[1:5, 1:6] ## CHA TRU VAI LOC OMB BLA ## 1 0 1.0000000 0.0000000 0.0000000 0 0 ## 2 0 0.6454972 0.5773503 0.5000000 0 0 ## 3 0 0.5590170 0.5590170 0.5590170 0 0 ## 4 0 0.4364358 0.4879500 0.4879500 0 0 ## 5 0 0.2425356 0.2970443 0.2425356 0 0 10.4 Z-score standardization Standardizing environmental variables is crucial as you cannot compare the effects of variables with different units: ## `?`(decostand) env.z &lt;- decostand(env, method = &quot;standardize&quot;) This centres and scales the variables to make your downstream analysis more appropriate: apply(env.z, 2, mean) ## das alt pen deb pH ## 1.000429e-16 1.814232e-18 -1.659010e-17 1.233099e-17 -4.096709e-15 ## dur pho nit amm oxy ## 3.348595e-16 1.327063e-17 -8.925898e-17 -4.289646e-17 -2.886092e-16 ## dbo ## 7.656545e-17 apply(env.z, 2, sd) ## das alt pen deb pH dur pho nit amm oxy dbo ## 1 1 1 1 1 1 1 1 1 1 1 We will see more details about this transformation in the next sections! 10.4.0.1 Little review Association - “general term to describe any measure or coefficient to quantify the resemblance or difference between objects or descriptors. In an analysis between descriptors, zero means no association.” (Legendre and Legendre 2012). Similarity - a measure that is “maximum (S=1) when two objects are identical and minimum when two objects are completely different.” (Legendre and Legendre 2012). Distance (also called dissimilarity) - a measure that is “maximum (D=1) when two objects are completely different”. (Legendre and Legendre 2012). Distance or dissimilarity (D) = 1-S Choosing an association measure depends on your data, but also on what you know, ecologically about your data. Here are some commonly used dissimilarity (distance) measures (recreated from Gotelli and Ellison 2004): Measure name Property Description Euclidean Metric Distance between two points in 2D space. Manhattan Metric Distance between two points, where the distance is the sum of differences of their Cartesian coordinates, i.e. if you were to make a right able between the points. Chord Metric This distance is generally used to assess differences due to genetic drift. Mahalanobis Metric Distance between a point and a set distribution, where the distance is the number of standard deviations of the point from the mean of the distribution. Chi-square Metric Similar to Euclidean. Bray-Curtis Semi-metric Dissimilarity between two samples (or sites) where the sum of lower values for species present in both samples are divided by the sum of the species counted in each sample. Jaccard Metric Description Sorensen's Semi-metric Bray-Curtis is 1 - Sorensen 10.4.0.2 Extra: environmental data set Quantitative environmental data Let’s look at associations between environmental variables (also known as Q mode): `?`(dist # this function also compute dissimilarity matrix ) env.de &lt;- dist(env.z, method = &quot;euclidean&quot;) # euclidean distance matrix of the standardized environmental variables windows() #Creates a separate graphical window coldiss(env.de, diag = TRUE) We can then look at the dependence between environmental variables (also known as R mode): (env.pearson &lt;- cor(env)) # Pearson r linear correlation round(env.pearson, 2) #Rounds the coefficients to 2 decimal points (env.ken &lt;- cor(env, method = &quot;kendall&quot;)) # Kendall tau rank correlation round(env.ken, 2) The Pearson correlation measures the linear correlation between two variables. The Kendall tau is a rank correlation which means that it quantifies the relationship between two descriptors or variables when the data are ordered within each variable. In some cases, there may be mixed types of environmental variables. Q mode can still be used to find associations between these environmental variables. We’ll do this by first creating an example dataframe: var.g1 &lt;- rnorm(30, 0, 1) var.g2 &lt;- runif(30, 0, 5) var.g3 &lt;- gl(3, 10) var.g4 &lt;- gl(2, 5, 30) (dat2 &lt;- data.frame(var.g1, var.g2, var.g3, var.g4)) str(dat2) summary(dat2) A dissimilarity matrix can be generated for these mixed variables using the Gower dissimilarity matrix: `?`(daisy #This function can handle NAs in the data ) (dat2.dg &lt;- daisy(dat2, metric = &quot;gower&quot;)) coldiss(dat2.dg) Challenge 1 - Advanced Calculate the Bray-Curtis and the Gower dissimilarity of species abundance CHA, TRU and VAI for sites 1, 2 and 3 (using the “spe” and “env” dataframes) without using the decostand() function. Challenge 1 - Advanced Solution &lt;hidden&gt; Subset the species data so that only sites 1, 2 are included and only the species CHA, TRU and VAI. spe.challenge &lt;- spe[1:3, 1:3] #”[1:3,” refers to rows 1 to 3 while “,1:3]” refers to the first 3 species columns (in #this case the three variables of interest) Determine total species abundance for each site of interest (sum of the 3 rows). This will be for the denominator in the above equation. (Abund.s1 &lt;- sum(spe.challenge[1, ])) (Abund.s2 &lt;- sum(spe.challenge[2, ])) (Abund.s3 &lt;- sum(spe.challenge[3, ])) # () around code will cause output to print right away in # console Now calculate the difference in species abundances for each pair of sites. For example, what is the difference between the abundance of CHA and TRU in site 1? You need to calculate the following differences: CHA and TRU site 1 CHA and VAI site 1 TRU and VAI site 1 CHA and TRU site 2 CHA and VAI site 2 TRU and VAI site 2 CHA and TRU site 3 CHA and VAI site 3 TRU and VAI site 3 Spec.s1s2 &lt;- 0 Spec.s1s3 &lt;- 0 Spec.s2s3 &lt;- 0 for (i in 1:3) { Spec.s1s2 &lt;- Spec.s1s2 + abs(sum(spe.challenge[1, i] - spe.challenge[2, i])) Spec.s1s3 &lt;- Spec.s1s3 + abs(sum(spe.challenge[1, i] - spe.challenge[3, i])) Spec.s2s3 &lt;- Spec.s2s3 + abs(sum(spe.challenge[2, i] - spe.challenge[3, i])) } Now take the differences you have calculated as the numerator in the equation for Bray-Curtis dissimilarity and the total species abundance that you already calculated as the denominator. (db.s1s2 &lt;- Spec.s1s2/(Abund.s1 + Abund.s2)) #Site 1 compared to site 2 (db.s1s3 &lt;- Spec.s1s3/(Abund.s1 + Abund.s3)) #Site 1 compared to site 3 (db.s2s3 &lt;- Spec.s2s3/(Abund.s2 + Abund.s3)) #Site 2 compared to site 3 You should find values of 0.5 for site 1 to site 2, 0.538 for site 1 to site 3 and 0.053 for site 2 to 3. Check your manual results with what you would find using the function vegdist() with the Bray-Curtis method: (spe.db.challenge &lt;- vegdist(spe.challenge, method = &quot;bray&quot;)) A matrix looking like this is produced, which should be the same as your manual calculations: Site 1 Site 2 Site 2 0.5 -- Site 3 0.538 0.0526 For the Gower dissimilarity, proceed in the same way but use the appropriate equation: # Calculate the number of columns in your dataset M &lt;- ncol(spe.challenge) # Calculate the species abundance differences between pairs # of sites for each species Spe1.s1s2 &lt;- abs(spe.challenge[1, 1] - spe.challenge[2, 1]) Spe2.s1s2 &lt;- abs(spe.challenge[1, 2] - spe.challenge[2, 2]) Spe3.s1s2 &lt;- abs(spe.challenge[1, 3] - spe.challenge[2, 3]) Spe1.s1s3 &lt;- abs(spe.challenge[1, 1] - spe.challenge[3, 1]) Spe2.s1s3 &lt;- abs(spe.challenge[1, 2] - spe.challenge[3, 2]) Spe3.s1s3 &lt;- abs(spe.challenge[1, 3] - spe.challenge[3, 3]) Spe1.s2s3 &lt;- abs(spe.challenge[2, 1] - spe.challenge[3, 1]) Spe2.s2s3 &lt;- abs(spe.challenge[2, 2] - spe.challenge[3, 2]) Spe3.s2s3 &lt;- abs(spe.challenge[2, 3] - spe.challenge[3, 3]) # Calculate the range of each species abundance between # sites Range.spe1 &lt;- max(spe.challenge[, 1]) - min(spe.challenge[, 1]) Range.spe2 &lt;- max(spe.challenge[, 2]) - min(spe.challenge[, 2]) Range.spe3 &lt;- max(spe.challenge[, 3]) - min(spe.challenge[, 3]) # Calculate the Gower dissimilarity (dg.s1s2 &lt;- (1/M) * ((Spe2.s1s2/Range.spe2) + (Spe3.s1s2/Range.spe3))) (dg.s1s3 &lt;- (1/M) * ((Spe2.s1s3/Range.spe2) + (Spe3.s1s3/Range.spe3))) (dg.s2s3 &lt;- (1/M) * ((Spe2.s2s3/Range.spe2) + (Spe3.s2s3/Range.spe3))) # Compare your results (spe.db.challenge &lt;- vegdist(spe.challenge, method = &quot;gower&quot;)) "],["clustering.html", "Chapter 11 Clustering 11.1 Single linkage agglomerative clustering 11.2 Complete linkage agglomerative clustering 11.3 Ward’s minimum variance clustering", " Chapter 11 Clustering One application of association matrices is clustering. Clustering highlights structures in the data by partitioning either the objects or the descriptors. As a result, similar objects are combined into groups, allowing distinctions – or contrasts – between groups to be identified. One goal of ecologists could be to divide a set of sitesinto groups with respect to their environmental conditions or their community composition. Clustering results are often represented as dendrograms (trees), where objects agglomerate into groups. There are several families of clustering methods, but for the purpose of this workshop, we will present an overview of three hierarchical agglomerative clustering methods: single linkage, complete linkage, and Ward’s minimum variance clustering. See Chapter 8 of Legendre and Legendre 2012 for more details on the different families of clustering methods. In hierarchical methods, elements of lower clusters (or groups) become members of larger, higher ranking clusters, e.g. species, genus, family, order. Prior to clustering, one needs to create an association matrix among the objects. Distance matrix is the default choice of clustering functions in R. The association matrix is first sorted in increasing distance order (or decreasing similarities). Then, groups are formed hierarchically following rules specific to each method. 11.1 Single linkage agglomerative clustering Let's take a simple example of a euclidean distance matrix between 5 objets which were sorted in ascending order. In single linkage agglomerative clustering (also called nearest neighbour sorting), the objects at the closest distances agglomerate. The two closest objects agglomerate first, the next two closest objects/clusters are then linked, and so on, which often generates long thin clusters or chains of objects (see how objets 1 to 5 cluster successively). Conversely, in complete linkage agglomerative clustering, an object agglomerates to a group only when linked to the furthest element of the group, which in turn links it to all members of that group (in the above example, the group formed of objets 3 and 4 only clusters with group 1-2 at 0.4, a distance at which objets 1, 2, 3 and 4 are all linked). As a result, complete linkage clustering will form many small separate groups, and is more appropriate to look for contrasts, discontinuities in the data. 11.2 Complete linkage agglomerative clustering Let’s compare the single and complete linkage clustering methods using the Doubs fish species data. Species data were already Hellinger-transformed. The cluster analysis requiring similarity or dissimilarity indices, the first step will be to generate the Hellinger distance indices. spe.dhel &lt;- vegdist(spe.hel, method = &quot;euclidean&quot;) #generates the distance matrix from Hellinger transformed data # See difference between the two matrices head(spe.hel) # Hellinger-transformed species data head(spe.dhel) # Hellinger distances among sites Most clustering methods can be computed with the function hclust() of the stats package. # Faire le groupement à liens simples Perform single # linkage clustering spe.dhel.single &lt;- hclust(spe.dhel, method = &quot;single&quot;) plot(spe.dhel.single) # Perform complete linkage clustering spe.dhel.complete &lt;- hclust(spe.dhel, method = &quot;complete&quot;) plot(spe.dhel.complete) Are there big differences between the two dendrograms? In single linkage clustering, chains of objets occur (e.g. 19, 29, 30, 20, 26, etc.), whereas more contrasted groups are formed in the complete linkage clustering. 11.3 Ward’s minimum variance clustering Ward’s minimum variance clustering differ from these two methods in that it clusters objects into groups using the criterion of least squares (similar to linear models). At the beginning, each object is considered being a cluster of its own. At each step, the pair of clusters merging is the one leading to minimum increase in total within-group sum of squares. Again, it is possible to generate a Ward’s minimum variance clustering with hclust(). However, the dendogram shows squared distances by default. In order to compare this dendrogram to the single and complete linkage clustering results, one must calculate the square root of the distances. # Perform Ward minimum variance clustering spe.dhel.ward &lt;- hclust(spe.dhel, method = &quot;ward.D2&quot;) plot(spe.dhel.ward) # Re-plot the dendrogram by using the square roots of the # fusion levels spe.dhel.ward$height &lt;- sqrt(spe.dhel.ward$height) plot(spe.dhel.ward) plot(spe.dhel.ward, hang = -1) # hang=-1 aligns all objets on the same line The clusters generated using Ward’s method tend to be more spherical and to contain similar numbers of objects. One must be careful in the choice of an association measure and clustering method in order to correctly address a problem. What are you most interested in: gradients? Contrasts? In addition, the results should be interpreted with respect to the properties of the method used. If more than one method seems suitable to an ecological question, computing them all and compare the results would be the way to go. As a reminder, clustering is not a statistical method, but further steps can be taken to identify interpretable clusters (e.g. where to cut the tree), or to compute clustering statistics. Clustering can also be combined to ordination in order to distinguish groups of sites. These go beyond the scope of this workshop, but see Borcard et al. 2011 for more details. "],["what-does-unconstrained-mean.html", "Chapter 12 What does “unconstrained” mean?", " Chapter 12 What does “unconstrained” mean? Unconstrained ordination allows us to organize samples, sites or species along continuous gradients (e.g. ecological or environmental). The key difference between unconstrained and constrained ordination (discussed later in this workshop- see ‘Canonical Ordination’) is that in the unconstrained techniques we are not attempting to define a relationship between independent and dependent sets of variables. Unconstrained ordination can be used to: Assess relationships within a set of variables (not between sets). Find key components of variation between samples, sites, species etc. Reduce the number dimensions in multivariate data without substantial loss of information. Create new variables for use in subsequent analyses (such as regression). These principal components are weighted, linear combinations of the original variables in the ordination. Source "],["principal-component-analysis.html", "Chapter 13 Principal Component Analysis", " Chapter 13 Principal Component Analysis Principal component analysis (PCA) was originally described by Pearson (1901) although it is more often attributed to Hotelling (1933) who proposed it independently. The method and several of its implications for data analysis are presented in the seminal paper of Rao (1964). PCA is used to generate a few key variables from a larger set of variables that still represent as much of the variation in the dataset as possible. PCA is a powerful technique to analyze quantitative descriptors (such as species abundances), but cannot be applied to binary data (such as species absence/presence). Based on a dataset containing normally distributed variables, the first axis (or principal-component axis) of a PCA is the line that goes through the greatest dimension of the concentration ellipsoid describing the multinormal distribution. Similarly, the following axes go through the dimensions of the concentration ellipsoid by decreasing length. One can thus derive a maximum of p principal axes form a data set containing p variables. For this, PCA rotates the original system of axes defined by the variables in a way that the successive new axes are orthogonal to one another and correspond to the successive dimensions of maximum variance of the scatter of points. The new variables produced in a PCA are uncorrelated with each other (axes are orthogonal to each other) and therefore may be used in other analyses such as multiple regression (Gotelli and Ellison 2004). The principal components give the positions of the objects in the new system of coordinates. PCA works on an association matrix among variables containing the variances and covariances of the variables. PCA preserves Euclidean distances and detects linear relationships. As a consequence, raw species abundance data are subjected to a pre-transformation (i.e. a Hellinger transformation) before computing a PCA. To do a PCA you need: - A set of variables (with no distinction between independent or dependent variables, i.e. a set of species OR a set of environmental variables). - Samples that are measured for the same set of variables. - Generally a dataset that is longer than it is wide is preferred. PCA is most useful with data with more than two variables, but is easier to describe using a two dimensional example. In this example (derived from Clarke and Warwick 2001) , we have nine sites with abundance data for two species: Site Species 1 Species 2 A 6 2 B 0 0 C 5 8 D 7 6 E 11 6 F 10 10 G 15 8 H 18 14 I 14 14 If you plotted these samples in the two dimensions, the plot would look like this: This is a straight forward scatter plot and is an ordination plot, but you can imagine that it is more difficult to produce and visualize such a plot if there were more than two species. In that case, you would want to reduce the number of variables to principal components. If the 2D plot above was too complex and we wanted to reduce the data into a single dimension, we would be doing so with a PCA: In this case, the first principal component is the line of best fit through the points (sites) with the sites perpendicular to the line. A second principal component is then added perpendicular to the first axis: The final plot then is the two PC axes rotated where the axes are now principal components as opposed to species: For PCAs with more than two variables, principal components are added like this (Clarke and Warwick 2001): PC1 = axis that maximises the variance of the points that are projected perpendicularly onto the axis. PC2 = must be perpendicular to PC1, but the direction is again the one in which variance is maximised when points are perpendicularly projected. PC3 and so on: perpendicular to the first two axes. Essentially, when there are more than two dimensions, PCA produces a new space in which all PCA axes are orthogonal (e.g. where the correlation among any two axes is null) and where the PCA axes are ordered according to the percent of the variance of the original data they explain. The “spe” data includes 27 fish taxa. To simplify the 27 fish taxa into a smaller number of fish-related variables or to identify where different sites or samples are associated with particular fish taxa we can run a PCA. Run a PCA on Hellinger-transformed species data: # Run the PCA using the rda() function (NB: rda() is used # for both PCA and RDA) spe.h.pca &lt;- rda(spe.hel) # Extract the results summary(spe.h.pca) #overall results The summary looks like this: Interpretation of ordination results: A new word from this output is \"eigenvalue\". An eigenvalue is the value of the change in the length of a vector, and for our purposes is the amount of variation explained by each axis in a PCA. As you can see, the summary function produces a fair amount of information. From the summary we can see how much of the variance in the data is explained by the unconstrained variables (i.e. variables where we have made no effort to define relationships between the variables). In this case, the total variance of the sites explained by the species is 0.5. The summary also tells you what proportion of the total explained variance is explained by each principal component in the PCA: the first axis of the PCA thus explains 51.33% of the variation, and the second axis 12.78%. You can also extract certain parts of the output, try this: summary(spe.h.pca, display = NULL) # only eigenvalues and their contribution to the variance eigen(cov(spe.hel)) # also compute the eigenvalues Sometimes you may want to extract the scores (i.e. the coordinates within a PCA biplot) for either the “sites” (the rows in your dataset, whether they be actual sites or not) or the “species” (the variables in your data, whether they be actual species or some other variables). This is useful if you want to then use a principal component as a variable in another analysis, or to make additional graphics. For example, with the “spe” dataset, you might want to obtain a single variable that is a composite of all the fish abundance data and then use that use that variable in a regression with another variable, or plot across a spatial gradient. To extract scores from a PCA, use the scores() function: spe.scores &lt;- scores(spe.h.pca, display = &quot;species&quot;, choices = c(1, 2)) # species scores on the first two PCA axes site.scores &lt;- scores(spe.h.pca, display = &quot;sites&quot;, choices = c(1, 2)) # sites scores on the first two PCA axes # Note: if you don’t specify the number of principal # components to extract (e.g. choices=c(1,2) or # choices=c(1:2) then all of the scores will be extracted # for all of the principal components. The PCA on the “spe” fish data produces as many principal components as there are fish taxon (columns), which in this case means that 27 principal components are produced. In many cases though, you may have done a PCA to reduce the number of variables to deal with and produce composite variables for the fish. In this case, you are likely interested in knowing how many of these principal components are actually significant or adding new information to the PCA (i.e. how many principal components do you need to retain before you aren’t really explaining any more variance with the additional principal components). To determine this, you can use the Kaiser-Guttman criterion and produce a barplot showing at what point the principal components are no longer explaining significant amount of variance. The code for the barplot below shows the point at which the variance explained by a new principal component explains less than the average amount explained by all of the eigenvalues: # Identify the significant axis using the Kaiser-Guttman # criterion ev &lt;- spe.h.pca$CA$eig ev[ev &gt; mean(ev)] n &lt;- length(ev) barplot(ev, main = &quot;Eigenvalues&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Average eigenvalue&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) From this barplot, you can see that once you reach PC6, the proportion of variance explained falls below the average proportion explained by the other components. If you take another look at the PCA summary, you will notice that by the time you reach PC5, the cumulative proportion of variance explained by the principal components is 85%. A PCA is not just for species data. It can also be run and interpreted in the same way using standardized environmental variables: # Run the PCA env.pca &lt;- rda(env.z) # or rda(env, scale=TRUE) # Extract the results summary(env.pca) summary(env.pca, scaling = 2) Scaling refers to what portion of the PCA is scaled to the eigenvalues. Scaling = 2 means that the species scores are scaled by eigenvalues, whereas scaling = 1 means that site scores are scaled by eigenvalues. Scaling = 3 means that both species and site scores are scaled symmetrically by square root of eigenvalues. Using scaling = 1 means that the Euclidean distances among objects (e.g. the rows in your data) are preserved, whereas scaling = 2 means that the correlations amongst descriptors (e.g. the columns in this data) are preserved. This means that when you look at a biplot of a PCA that has been run with scaling=2, the angle between descriptors represents correlation. # Identify the significant axis using the Kaiser-Guttman # criterion ev &lt;- env.pca$CA$eig ev[ev &gt; mean(ev)] n &lt;- length(ev) barplot(ev, main = &quot;Eigenvalues&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Average eigenvalue&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) Compare this eigenvalue barplot with the one you created for the species PCA. As you saw in the explanation of the summary output, a lot of information can be extracted from a PCA before even plotting it. However, many of us interpret data best visually and a figure of a PCA is often the best way to convey major patterns. PCA biplots can be plotted in base R. A PCA biplot includes the x-axis as the first Principal Component and the y-axis as the second Principal Component. For some plotting exercises, let's start with the species PCA. A basic biplot without any customization could be plotted like this, where the site positions are shown by black numbers and species’ positions are shown by red species codes. Remember, species positions come from plotting species along PCs and the site positions are derived from the weighted sums of species scores. plot(spe.h.pca) Basically, the plot above plots the PCA like this: plot(spe.h.pca, type = &quot;n&quot;) #produces a blank biplot with nothing displayed but the axes points(spe.h.pca, dis = &quot;sp&quot;, col = &quot;blue&quot;) #points are added for the species (columns) (dis=) # use text() instead of points() if you want the labels points(spe.h.pca, dis = &quot;sites&quot;, col = &quot;red&quot;) #points are added for the sites (rows) To create more detailed plots and to play with aesthetics, try this code: #Biplot of the PCA on transformed species data (scaling 1) windows() plot(spe.h.pca) windows() biplot(spe.h.pca) windows() plot(spe.h.pca, scaling=1, type=&quot;none&quot;, # scaling 1 = distance biplot : # distances among objects in the biplot approximate their Euclidean distances # but angles among descriptor vectors DO NOT reflect their correlation xlab = c(&quot;PC1 (%)&quot;, round((spe.h.pca$CA$eig[1]/sum(spe.h.pca$CA$eig))*100,2)), #this comes from the summary ylab = c(&quot;PC2 (%)&quot;, round((spe.h.pca$CA$eig[2]/sum(spe.h.pca$CA$eig))*100,2))) points(scores(spe.h.pca, display=&quot;sites&quot;, choices=c(1,2), scaling=1), pch=21, col=&quot;black&quot;, bg=&quot;steelblue&quot;, cex=1.2) text(scores(spe.h.pca, display=&quot;species&quot;, choices=c(1), scaling=1), scores(spe.h.pca, display=&quot;species&quot;, choices=c(2), scaling=1), labels=rownames(scores(spe.h.pca, display=&quot;species&quot;, scaling=1)), col=&quot;red&quot;, cex=0.8) This code produces 3 plots, the final plot is the most visually pleasing: What conclusions can you draw from this plot? From the plot, you can see the site scores shown by the blue dots. If you superimposed site labels on top, you could see what sites are closer to each other in terms of the species found at those sites, but even without the specific labels, you can see that there are only a few sites that are farther away from the majority. The species names are shown by their names in red and from the plot, you can see for example that the species \"ABL\" is not found or not found in the same prevalence in the majority of sites as other species closer to the centre of the ordination. Biplots need to be interpreted in terms of angles from center of plot, not just in terms of proximity. Two variables at 90 degree angle are uncorrelated. Two variables in opposing directions are negatively correlated. Two variables very close together are strongly correlated, at least in the space described by these axes. Now let's look at a plot of the environmental PCA: #Biplot of the PCA on the environmental variables (scaling 2) windows() plot(env.pca) windows() plot(env.pca, scaling=2, type=&quot;none&quot;, # scaling 2 = correlation biplot : # distances among abjects in the biplot DO NOT approximate their Euclidean distances # but angles among descriptor vectors reflect their correlation xlab = c(&quot;PC1 (%)&quot;, round((env.pca$CA$eig[1]/sum(env.pca$CA$eig))*100,2)), ylab = c(&quot;PC2 (%)&quot;, round((env.pca$CA$eig[2]/sum(env.pca$CA$eig))*100,2)), xlim = c(-1,1), ylim=c(-1,1)) points(scores(env.pca, display=&quot;sites&quot;, choices=c(1,2), scaling=2), pch=21, col=&quot;black&quot;, bg=&quot;darkgreen&quot;, cex=1.2) text(scores(env.pca, display=&quot;species&quot;, choices=c(1), scaling=2), scores(env.pca, display=&quot;species&quot;, choices=c(2), scaling=2), labels=rownames(scores(env.pca, display=&quot;species&quot;, scaling=2)), col=&quot;red&quot;, cex=0.8) Remember that a PCA biplot is really just a scatter plot, where the axes are scores extracted from composite variables. This means that there are many different ways you can plot a PCA. For example, try using your ggplot() skills from Workshop 4 to extract PCA scores and plot an ordination in ggplot. Use of PCA axis as composite explanatory variables: In some cases, users want to reduce several environmental variables in a few numbers of composite variables. When PCA axes represent ecological gradients (i.e. when environmental variables are correlated with PCA axis in a meaningful way), users can use site scores along PCA Axis in further analyses instead of the raw environmental data. In other words, sites scores along PCA Axis represent linear combinations of descriptors and can consequently be used as proxy of ecological conditions in “post-ordination” analyses. In the example above, the first PCA axis can be related to a gradient from oligotrophic, oxygen-rich to eutrophic, oxygen-deprived water: from left to right, a first group display the highest values of altitude (alt) and slope (pen), and the lowest values in river discharge (deb) and distance from the source (das). The second group of sites has the highest values in oxygen content (oxy) and the lowest in nitrate concentration (nit). A third group shows intermediate values in almost all the measured variables. If users are then interested in identifying if a specific species is associated with ologotrophic or eutrophic water, one can correlate the species abundances to sites scores along PCA Axis 1. For example, if one want to assess if the species TRU prefers oligotrophic or eutrophic water, the following linear model can be used : Sites_scores_Env_Axis1 &lt;- scores(env.pca, display = &quot;sites&quot;, choices = c(1), scaling = 2) spe$ANG plot(Sites_scores_Env_Axis1, spe$TRU) summary(lm(spe$TRU ~ Sites_scores_Env_Axis1)) abline(lm(spe$TRU ~ Sites_scores_Env_Axis1)) This simple model shows that the abundance of species TRU is significantly dependent of site scores along PCA axis 1 (t = -5.30, p = 1.35e-05, adj-R2 = 49.22%), i.e. depends of an oligotrophic-eutrophic gradient. The following plot identifies a preference of this species for oligotrophic water. Challenge 3 Run a PCA of the “mite” species abundance data. What are the significant axes of variation? Which groups of sites can you identify? Which species are related to each group of sites? Use: mite.spe &lt;- mite #mite data is from the vegan package Challenge 3 - Solution &lt;hidden&gt; Your code likely looks something like the following. # Hellinger transformation of mite data and PCA mite.spe.hel &lt;- decostand(mite.spe, method = &quot;hellinger&quot;) mite.spe.h.pca &lt;- rda(mite.spe.hel) # What are the significant axes? ev &lt;- mite.spe.h.pca$CA$eig ev[ev &gt; mean(ev)] n &lt;- length(ev) barplot(ev, main = &quot;Eigenvalues&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Average eigenvalue&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) # Output summary/results summary(mite.spe.h.pca, display = NULL) windows() # Plot the biplot plot(mite.spe.h.pca, scaling = 1, type = &quot;none&quot;, xlab = c(&quot;PC1 (%)&quot;, round((mite.spe.h.pca$CA$eig[1]/sum(mite.spe.h.pca$CA$eig)) * 100, 2)), ylab = c(&quot;PC2 (%)&quot;, round((mite.spe.h.pca$CA$eig[2]/sum(mite.spe.h.pca$CA$eig)) * 100, 2))) points(scores(mite.spe.h.pca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 1), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(mite.spe.h.pca, display = &quot;species&quot;, choices = c(1), scaling = 1), scores(mite.spe.h.pca, display = &quot;species&quot;, choices = c(2), scaling = 1), labels = rownames(scores(mite.spe.h.pca, display = &quot;species&quot;, scaling = 1)), col = &quot;red&quot;, cex = 0.8) And your resulting biplot likely looks something like this: A dense cluster of related species and sites can be seen in the biplot. &lt;/hidden&gt; "],["correspondence-analysis.html", "Chapter 14 Correspondence Analysis", " Chapter 14 Correspondence Analysis One of the key assumptions made in PCA is that species are related to each other linearly and that they respond linearly to ecological gradients. This is not necessarily the case with a lot of ecological data (e.g. many species have unimodal species distributions). Using PCA on data with unimodal species distributions or a lot of zero values may lead to a phenomenon called the “horseshoe effect”, and can occur with long ecological gradients. As such, a CA or Correspondence Analysis may be a better option for this type of data, see Legendre and Legendre (2012) for further information. As CA preserves Chi2 distances (while PCA preserves Euclidean distances), this technique is indeed better suited to ordinate datasets containing unimodal species distributions, and has, for a long time, been one of the favourite tools for the analysis of species presence–absence or abundance data. In CA, the raw data are first transformed into a matrix Q of cell-by-cell contributions to the Pearson Chi2 statistic, and the resulting table is submitted to a singular value decomposition to compute its eigenvalues and eigenvectors. The result is an ordination, where it is the Chi2 distance that is preserved among sites instead of the Euclidean distance in PCA. The Chi2 distance is not influenced by the double zeros. Therefore, CA is a method adapted to the analysis of species abundance data without pre-transformation. Contrary to PCA, CA can also be applied to analyze both quantitative and binary data (such as species abundances or absence/presence). As in PCA, the Kaiser-Guttman criterion can be applied to determine the significant axes of a CA, and ordination axes can be extracted to be used in multiples regressions. Run a CA on species data: # Run the CA using the cca() function (NB: cca() is used # for both CA and CCA) spe.ca &lt;- cca(spe) # Identify the significant axes ev &lt;- spe.ca$CA$eig ev[ev &gt; mean(ev)] n = length(ev) barplot(ev, main = &quot;Eigenvalues&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Average eigenvalue&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) From this barplot, you can see that once you reach C6, the proportion of variance explained falls below the average proportion explained by the other components. If you take another look at the CA summary, you will notice that by the time you reach CA5, the cumulative proportion of variance explained by the principal components is 84.63%. summary(spe.h.pca) #overall results summary(spe.h.pca, diplay = NULL) # only axis eigenvalues and contribution CA results are presented in a similar manner as PCA results. You can see here that CA1 explains 51.50% of the variation in species abundances, while CA2 explain 12.37% of the variation. par(mfrow = c(1, 2)) #### scaling 1 plot(spe.ca, scaling = 1, type = &quot;none&quot;, main = &quot;CA - biplot scaling 1&quot;, xlab = c(&quot;CA1 (%)&quot;, round((spe.ca$CA$eig[1]/sum(spe.ca$CA$eig)) * 100, 2)), ylab = c(&quot;CA2 (%)&quot;, round((spe.ca$CA$eig[2]/sum(spe.ca$CA$eig)) * 100, 2))) points(scores(spe.ca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 1), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(spe.ca, display = &quot;species&quot;, choices = c(1), scaling = 1), scores(spe.ca, display = &quot;species&quot;, choices = c(2), scaling = 1), labels = rownames(scores(spe.ca, display = &quot;species&quot;, scaling = 1)), col = &quot;red&quot;, cex = 0.8) #### scaling 2 plot(spe.ca, scaling = 1, type = &quot;none&quot;, main = &quot;CA - biplot scaling 2&quot;, xlab = c(&quot;CA1 (%)&quot;, round((spe.ca$CA$eig[1]/sum(spe.ca$CA$eig)) * 100, 2)), ylab = c(&quot;CA2 (%)&quot;, round((spe.ca$CA$eig[2]/sum(spe.ca$CA$eig)) * 100, 2)), ylim = c(-2, 3)) points(scores(spe.ca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 2), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(spe.ca, display = &quot;species&quot;, choices = c(1), scaling = 2), scores(spe.ca, display = &quot;species&quot;, choices = c(2), scaling = 2), labels = rownames(scores(spe.ca, display = &quot;species&quot;, scaling = 2)), col = &quot;red&quot;, cex = 0.8) These biplots show that a group of sites located in the left part with similar fish community characterized by numerous species such as GAR, TAN, PER, ROT, PSO and CAR; in the upper right corner, an other site cluster characterized by the species LOC, VAI and TRU is identified; the last site cluster in the lower right corner of the biplot is characterized by the species BLA, CHA and OMB. Challenge 4 Run a CA of the “mite” species abundance data. What are the significant axes of variation? Which groups of sites can you identify? Which species are related to each group of sites? Challenge 4 - Solution &lt;hidden&gt; Your code likely looks something like the following: # CA on mite species mite.spe.ca &lt;- cca(mite.spe) # What are the significant axes ? ev &lt;- mite.spe.ca$CA$eig ev[ev &gt; mean(ev)] n = length(ev) barplot(ev, main = &quot;Eigenvalues&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Average eigenvalue&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) # Output summary/results summary(mite.spe.ca, display = NULL) # Plot the biplot windows() plot(mite.spe.ca, scaling = 1, type = &quot;none&quot;, xlab = c(&quot;PC1 (%)&quot;, round((mite.spe.ca$CA$eig[1]/sum(mite.spe.ca$CA$eig)) * 100, 2)), ylab = c(&quot;PC2 (%)&quot;, round((mite.spe.ca$CA$eig[2]/sum(mite.spe.ca$CA$eig)) * 100, 2))) points(scores(mite.spe.ca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 1), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(mite.spe.ca, display = &quot;species&quot;, choices = c(1), scaling = 1), scores(mite.spe.ca, display = &quot;species&quot;, choices = c(2), scaling = 1), labels = rownames(scores(mite.spe.ca, display = &quot;species&quot;, scaling = 1)), col = &quot;red&quot;, cex = 0.8) And your resulting biplot likely looks something like this: &lt;/hidden&gt; "],["principal-coordinates-analysis.html", "Chapter 15 Principal Coordinates Analysis", " Chapter 15 Principal Coordinates Analysis PCA as well as CA impose the distance preserved among objects: the Euclidean distance (and several others with pre-transformations) for PCA and the Chi2 distance for CA. If one wishes to ordinate objects on the basis of another distance measure, more appropriate to the problem at hand, then PCoA is the method of choice. In PCA we rotated and plotted our data so that as much variation was explained by a first Principal Component and we can see how much \"species\", either actual species or environmental variables, contribute to each component by looking at the scores (also called loadings). Another type of unconstrained ordination is called Principal Coordinate Analysis (PCoA). In PCoA, points are added to plane space one at a time using Euclidean distance (or whatever distance (dissimilarity) metric you choose). Basically, one point is added, then a second so that it's distance is correct from the first point and then the third point and so on adding as many axes (dimensions) as necessary along the way. Choosing between PCA and PCoA can be tricky, but generally PCA is used to summarize multivariate data into as few dimensions as possible, whereas PCoA can be used to visualize distances between points. PCoA can be particularly suited for datasets that have more columns than rows. For example, if hundreds of species have been observed over a set of quadrats, then a approach based on a PCoA using Bray-Curtis similarity (see below) may be best suited. Run a PCoA on the Hellinger transformed species abundances (back to DoubsSpe): #Using cmdscale() ?cmdscale cmdscale(dist(spe.hel), k=(nrow(spe)-1), eig=TRUE) #Using pcoa() ?pcoa spe.h.pcoa &lt;- pcoa(dist(spe.hel)) # Extract the results spe.h.pcoa #Construct the biplot biplot.pcoa(spe .h.pcoa, spe.hel, dir.axis2=-1) The output looks like this (and here here is a video that might help with the explanation of eigenvalues in terms of ordination): And the PCoA biplot, like this: You can also run a PCoA using a different distance measure (e.g. Bray-Curtis). Here is a PCoA run on a Bray-Curtis dissimilarity matrix: spe.bray.pcoa &lt;- pcoa(spe.db) #where spe.db is the species dissimilarity matrix using Bray-Curtis. spe.bray.pcoa biplot.pcoa(spe.bray.pcoa, spe.hel, dir.axis2 = -1) # Note that the distance measure chosen strongly influences # the results. Challenge 5 Run a PCoA on the Hellinger-transformed mite species abundance data. What are the significant axes? Which groups of sites can you identify? Which species are related to each group of sites? How do the PCoA results compare with the PCA results? Challenge 5 - Solution &lt;hidden&gt; Your code likely looks something like this: mite.spe.h.pcoa &lt;- pcoa(dist(mite.spe.hel)) mite.spe.h.pcoa windows() biplot.pcoa(mite.spe.h.pcoa, mite.spe.hel, dir.axis2 = -1) And your biplot like this: We see that species 16 and 31 are farther away from other species in terms of distance and therefore their distribution across the sites is highly dissimilar from the other species of mites (and each other). Site labels that practically overlap each other are good examples of sites with low dissimilarity (i.e. high similarity) to each other in terms of the species that are found at those sites. &lt;/hidden&gt; "],["nonmetric-multidimensional-scaling.html", "Chapter 16 Nonmetric MultiDimensional Scaling", " Chapter 16 Nonmetric MultiDimensional Scaling The unconstrained ordination methods presented above allow to organize objects (e.g. sites) characterized by descriptors (e.g. species) in full-dimensional space. In other words, PCA, CA and PCoA computes a large number of ordination axes (proportional to the number of descriptors) representing the variation of descriptors among sites and preserve distance among objects (the Euclidean distances in PCA, the Chi2 distances in CA and the type of distances defined by the user in PCoA). Users can then select the axis of interest (generally the first two ones as the explained the larger part of the variation) to represent objects in an ordination plot. The produced biplot thus represents well the distance among objects (e.g. the between-sites similarity), but fails to represent the whole variation dimensions of the ordination space (as Axis3, Axis4,…, Axisn are not represented on the biplot, but still contribute to explain the variation among objects). In some case, the priority is not to preserve the exact distances among sites, but rather to represent as accurately as possible the relationships among objects in a small and number of axes (generally two or three) specified by the user. In such cases, nonmetric multidimensional scaling (NMDS) is the solution. If two axes are selected, the biplot produced from NMDS is the better 2D graphical representation of between-objects similarity: dissimilar objects are far apart in the ordination space and similar objects close to one another. Moreover, NMDS allows users to choose the distance measure applied to calculate the ordination. To find the best representation of objects, NMDS applies an iterative procedure that tries to position the objects in the requested number of dimensions in such a way as to minimize a stress function (scaled from 0 to 1) which measure the goodness-of-fit of the distance adjustment in the reduced-space configuration. Consequently, the lower the stress value, the better the representation of objects in the ordination-space is. An additional way to assess the appropriateness of an NDMS is to construct a Shepard diagram which plot distances among objects in the ordination plot against the original distances. The R2 obtained from the regression between these two distances measure the goodness-of-fit of the NMDS ordination. # Run the NMDS spe.nmds &lt;- metaMDS(spe, distance = &quot;bray&quot;, k = 2) ### Extract the results spe.nmds ### Assess the goodness of fit and draw a Shepard plot spe.nmds$stress stressplot(spe.nmds, main = &quot;Shepard plot&quot;) # Construct the biplot windows() plot(spe.nmds, type = &quot;none&quot;, main = paste(&quot;NMDS/Bray - Stress=&quot;, round(spe.nmds$stress, 3)), xlab = c(&quot;NMDS1&quot;), ylab = c(&quot;NMDS2&quot;)) points(scores(spe.nmds, display = &quot;sites&quot;, choices = c(1, 2)), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(spe.nmds, display = &quot;species&quot;, choices = c(1)), scores(spe.nmds, display = &quot;species&quot;, choices = c(2)), labels = rownames(scores(spe.nmds, display = &quot;species&quot;)), col = &quot;red&quot;, cex = 0.8) The Shepard plot identifies a strong correlation between observed dissimilarity and ordination distance (R2 &gt; 0.95), highlighting a high goodness-of-fit of the NMDS. The biplot of the NMDS shows a group of closed sites characterized by the species BLA, TRU, VAI, LOC, CHA and OMB, while the other species form a cluster of sites in the upper right part of the graph. Four sites in the lower part of the graph are strongly different from the others. Challenge 6 Run the NMDS of the mite species abundances in 2 dimensions based on a Bray-Curtis distance. Assess the goodness-of-fit of the ordination and interpret the biplot. Challenge 6 - Solution &lt;hidden&gt; Your code likely looks something like this: mite.spe.nmds &lt;- metaMDS(mite.spe, distance = &quot;bray&quot;, k = 2) ### Extract the results mite.spe.nmds ### Assess the goodness of fit mite.spe.nmds$stress stressplot(mite.spe.nmds, main = &quot;Shepard plot&quot;) ### Construct the biplot windows() plot(mite.spe.nmds, type = &quot;none&quot;, main = paste(&quot;NMDS/Bray - Stress=&quot;, round(mite.spe.nmds$stress, 3)), xlab = c(&quot;NMDS1&quot;), ylab = c(&quot;NMDS2&quot;)) points(scores(mite.spe.nmds, display = &quot;sites&quot;, choices = c(1, 2)), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(mite.spe.nmds, display = &quot;species&quot;, choices = c(1)), scores(mite.spe.nmds, display = &quot;species&quot;, choices = c(2)), labels = rownames(scores(mite.spe.nmds, display = &quot;species&quot;)), col = &quot;red&quot;, cex = 0.8) And your plots like this: The correlation between observed dissimilarity and ordination distance (R2 &gt; 0.91) and the stress value relatively low, showing together a good accuracy of the NMDS ordination. No cluster of sites can be precisely defined from the NMDS biplot showing that most of the species occurred in most of the sites, i.e. a few sites shelter specific communities. &lt;/hidden&gt; "],["summary.html", "Chapter 17 Summary", " Chapter 17 Summary Ordination is a powerful statistical tecnhique for studying the relationships of objects characterized by several descriptors (e.g. sites described by biotic communities, or environmental variables), but serveral ordination methods exist. These methods mainly differ in the type of distance preserved, the type of variables allowed and the dimensions of the ordination space. To better guide your choice of the ordination method to use, the following table identify the main characteristics of the four ordination methods presented : In the next workshop, you will see how to identify the relationships between biotic communities and sets of environmental variables describing the same sites, using canonical analyses. "],["additional-resources.html", "Chapter 18 Additional resources", " Chapter 18 Additional resources "],["references.html", "Chapter 19 References", " Chapter 19 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
