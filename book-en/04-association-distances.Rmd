# (PART\*) (Dis)similarity measures {-}

# `dist()` 

Community resemblance is almost always assessed on the basis of species composition data in the form of a site-by-species data table $Y_{m,n}$.

We can obtain an association matrix $A_{m,m}$ in the form of pairwise distances or dissimilarities $D_{m,m}$ (or similarities $S_{m,m}$) and then analyse those distances. Association matrices between objects or among descriptors allow for
calculations of similarity or distances between objects or descriptors
(Legendre and Legendre 2012). 

In `R`, we can compute distance or dissimilarity matrices using `stats::dist()`. 
For simplicity, let us do this without specifying arguments:

```{r, eval = T, results='hide'}
dist(spe)
```

Run `dist(spe)` from your end, and you should observe that the output from `dist(spe) is a _lower triangular matrix_ representing pairwise associations between the columns of your original matrix.

Let us see what the commands below show us:

```{r, eval = T}
class(dist(spe))
```

```{r, eval = F}
str(dist(spe))
```

```{r, eval = F}
as.matrix(dist(spe))
```

```{r, eval = T}
dim(as.matrix(dist(spe)))
```

# Types of distance coefficients

There are three groups of distance coefficients: _metrics_, _semimetrics_, and _nonmetrics_ .

## Metric distances

The first group consists of *metrics*, and its coefficients satisfy the following properties:

1. minimum 0: if species $a$ is equal to species $b$, then $D(a,b)=0$;

2. positiveness: if $a \neq b$, then $D(a,b) > 0$;

3. symmetry: $D(a,b) = D(b,a)$;

4. triangle inequality: $D(a,b) + D(b,c) \geq D(a,c)$. The sum of two sides of a triangle drawn in the Euclidean space is equal or greater than the third side.

We can spot all these properties below:

```{r, eval = T}
as.matrix(dist(spe))[1:3, 1:3]
```

### Euclidean distances

The most common metric distance measure is the _Euclidean distance_.

It is computed using the Pythagorean formula:

$$D_{1} (x_1,x_2) = \sqrt{\sum_{j=1}^p(y_{1j} - y_{2j})^2}$$

```{r echo=FALSE}
#setting up the plot
xlim <- c(0,4)
ylim <- c(-1,5)
par(mar=c(1,1,1,1)+.1)
plot(xlim, 
     ylim, type="n", 
     xlab="X1", 
     ylab="X2", 
     asp=1)
grid()
# define some vectors
a=c(4, 0)
b=c(0, 4)
# plot the vectors
vectors(a, labels="D(y21, y11)", pos.lab=3, frac.lab=.5, col="grey")
vectors(a + b, labels="D1(x1,x2)", pos.lab=4, frac.lab=.5, col="red")
# vector a+b starting from a is equal to b.
vectors(a + b, labels="D(y12, y22)", pos.lab=4, frac.lab=.5, origin=a, col="grey")

points(x = 4, y = 0, type = "p")
text(x=4.1, y=-0.2, labels="")

points(x = 0, y = 0, type = "p")
text(x=-0.1, y=-0.2, labels="x1")

points(x = 4, y = 4, type = "p")
text(x=4.1, y=4.2, labels="x2")
```

Using `stats::dist()`, we can compute it with:

```{r, eval = T}
spe.D.Euclid <- dist(x = spe,  
                     method = "euclidean")
```

And, we can test whether a distance is Euclidean using:

```{r, eval = T}
is.euclid(spe.D.Euclid)
```

### Challenge #1

**Your turn!** Using the `dist()` function, compute the Euclidean distance matrix $D_{hmm}$ for the species abundances by site matrix $Y_{hmm}$ below:

| Sites | $y_1$ | $y_2$ | $y_3$ |
|:----: | :----:| :---: | :---: |
| $s_1$ | 0 | 4 | 8 |
| $s_2$ | 0 | 1 | 1 |
| $s_3$ | 1 | 0 | 0 |

```{r, eval = T}
Y.hmm <- data.frame(
  y1 = c(0, 0, 1),
  y2 = c(4, 1, 0),
  y3 = c(8, 1, 0))
```

After this, look into the numbers, think critically about them!

**Solution:**

You should have something similar to this:

```{r, eval = T}
Y.hmm.DistEu <- dist(x = Y.hmm,  
                     method = "euclidean")

as.matrix(Y.hmm.DistEu)
```

_Now, look into the composition and the distances between sites $s_2$ and $s_3$ and between $s_1$ and $s_2$. What is going on?_

The Euclidean distance between sites $s_2$ and $s_3$, which have no species in common, is smaller than the distance between $s_1$ and $s_2$, which share species $y_2$ and $y_3$ (!).

From an ecological perspective, _this is a problematic_ assessment of the relationship among sites.

This issue is known as the **double-zero problem**, _i.e._ double zeroes are treated in the same way as double presences, so that the double zeros shrink the distance between two sites.

Euclidean distances ( $D_1$ ) should thus _not_ be used to compare sites based on species abundances.


### Chord distances

Orlóci (1967) proposed the _Chord distance_ to analyse community composition.

It consists of:

1\. Normalizing the data, _i.e._ scaling site vectors to length 1 by dividing species abundances in a given sample by the square-rooted sum of square abundances in all samples as

$$y'_{Uj}=y_{Uj}/\sum^s_{j=1}{y^2_{Uj}}$$

2\. Calculating the Euclidean distances on this normalized data:

$$D_{3} (x_1,x_2) = \sqrt{\sum_{j=1}^p(y'_{1j} - y'_{2j})^2}$$

We can use `vegan::vegdist()` for this one:

```{r, eval = T}
spe.D.Ch <- vegdist(spe,  
                    method = "chord")

as.matrix(spe.D.Ch)[1:3, 1:3]
```

When two sites share the same species in the same proportions of the number of individuals the value of $D_3$ is $0$, and when no species are shared, its value is $\sqrt{2}$. 

_What happens if we compute Chord distances in the same site-by-species matrix $Y_{hmm}$?_

Let us try the Chord distances in the same matrix we used for Challenge #1:

```{r, eval = T}
Y.hmm.DistCh <- vegdist(Y.hmm,  
                    method = "chord")
```

```{r echo=TRUE}
as.matrix(Y.hmm.DistCh)
```

Now, let us compare with what we obtained when we used Euclidean distances:

```{r echo=TRUE}
as.matrix(Y.hmm.DistEu)
```

See again how our matrix looks:

```{r, eval = T}
Y.hmm
```

So, adding any number of double zeroes to a pair of sites does _not_ change the value of $D_3$. Hence, _Chord distances_ can be used to compare sites described by species abundances!


### Jaccard's coefficient

Another popular association coefficient is the _Jaccard similarity coefficient_ (1900).

It is only appropriate for **binary data**, and its distance coefficient is defined with the size of the intersection divided by the size of the union of the sample sets.

$$D_{7}(x_1,x_2) = 1 - \frac{\vert x_1 \cap x_2 \vert}{\vert x_1 \cup x_2 \vert} = 1 - \frac{\vert x_1 \cap x_2 \vert}{\vert x_1 \vert + \vert x_2 \vert - \vert x_1 \cap x_2 \vert} = 1-\frac{a}{a+b+c}$$
  
where,

- $a$ is the number of species shared between $x_1$ and $x_2$ that are coded $1$;
- $b$ is the number of occurrences where $x_1$ and $x_2$ are known to be different;
- $c$ is the number of common absences between $x_1$ and $x_2$, _i.e._ both $0$. 

For example, for sites $x_1$ and $x_2$:

| $x_1,x_2$ | $y_1$ | $y_2$ | $y_3$ | $y_4$ | $y_5$ |
|:----: | :----:| :---: | :---: | :---: | :---: |
| $x_1$ | 0 | 1 | 0 | 1 | 0 |
| $x_2$ | 0 | 1 | 1 | 1 | 1 |

So, we can calculate $a$, $b$, and $c$:
- $a$ = 1 + 1 = 2

- $b$ = 1 + 1 = 2

- $c$ = 1

And, then our distance coefficient:

$$D_{7}(x_1,x_2) = 1-\frac{2}{2+2+1}= 0.6$$

In `R`, you can use use the `vegan::vegdist()` function to calculate the Jaccard's coefficient:

```{r}
spe.D.Jac <- vegdist(spe, 
                     method = "jaccard",
                     binary = TRUE)
```

## Semimetric distances

The second group consists of *semimetrics*, and they violate the _triangle inequality_ property:

1. minimum 0: if species $a$ is equal to species $b$, then $D(a,b)=0$;

2. positiveness: if $a \neq b$, then $D(a,b) > 0$;

3. symmetry: $D(a,b) = D(b,a)$;

4. ~~triangle inequality~~: ${D(a,b) + D(b,c) \geq or < D(a,c)}$. The sum of two sides of a triangle drawn in the Euclidean space is _not_ equal or greater than the third side.

### Sørensen's coefficient

All parameters in _Jaccard's similarity coefficient_ have equal weights.

$$D_{7}(x_1,x_2)=1-\frac{a}{a+b+c}$$

However, you may want to consider that a presence of a species is more informative than its absence.

The distance corresponding to _Sørensen's similarity coefficient_ (1948) gives weight to double presences:

$$D_{13}(x_1,x_2)=1-\frac{2a}{2a+b+c}=\frac{b+c}{2a+b+c}$$

where,

- $a$ is the number of species shared between $x_1$ and $x_2$ that are coded $1$;
- $b$ is the number of occurrences where $x_1$ and $x_2$ are known to be different;
- $c$ is the number of common absences between $x_1$ and $x_2$, _i.e._ both $0$. 


In `R`, you can also use use the `vegan::vegdist()` function to calculate the Sørensen's coefficient:

```{r}
spe.D.Sor <- vegdist(spe, 
                     method = "bray",
                     binary = TRUE)
```

> Because both Jaccard's and Sørensen's are only appropriate for presence-absence data, you must binary-transform abundance data using `binary = TRUE` in `vegdist()`.

### Bray-Curtis' coefficient

The _Bray-Curtis dissimilarity coefficient_ is a modified version of the Sørensen's index and allows for species abundances:

$$D_{14}(x_1,x_2)=\frac{\sum{\vert y_{1j}-y_{2j}\vert}}{\sum{( y_{1j}+y_{2j})}}=$$

$$D_{14}(x_1,x_2)=1 - \frac{2W}{A+B}$$

where,

- $W$ is the sum of the lowest abundances in each species found between sites $x_1$ and $x_2$;

- $A$ is the sum of all abundances in $x_1$; and,

- $B$ is the sum of all abundances in $x_2$.

For example, for sites $x_1$ and $x_2$:

| $x_1,x_2$ | $y_1$ | $y_2$ | $y_3$ | $y_4$ | $y_5$ |
|:----: | :----:| :---: | :---: | :---: | :---: |
| $x_1$ | _2_ | _1_ | _0_ | 5 | 2 |
| $x_2$ | 5 | _1_ | 3 | _1_ | 1 |


So:
- $W = 2 + 1 + 0 + 1 + 1 = 5$

- $A = 2 + 1 + 0 + 5 + 0 = 8$

- $B = 5 + 1 + 3 + 1 + 2 = 12$

$$D_{14}(x_1,x_2) = 1-\frac{2 \times 5}{8+12} = 0.5$$

To calculate the _Bray-Curtis dissimilarity coefficient_, which can account for abundances, you need to set `binary = FALSE`.

```{r}
spe.db.pa <- vegdist(spe, 
                      method = "bray",
                      binary = FALSE)
spe.db <- as.matrix(spe.db.pa)
```

## Nonmetric distances

1. minimum 0: if species $a$ is equal to species $b$, then $D(a,b)=0$;

2. ~~positiveness:~~ if $a \neq b$, then $D(a,b) > or < 0$;

3. symmetry: $D(a,b) = D(b,a)$;

4. ~~triangle inequality~~: ${D(a,b) + D(b,c) \geq or < D(a,c)}$. The sum of two sides of a triangle drawn in the Euclidean space is _not_ equal or greater than the third side.

## Representation

We can create graphical depictions of association matrices using the `coldiss()` function:

```{r, echo = FALSE}
# coldiss() function
# Color plots of a dissimilarity matrix, without and with ordering
#
# License: GPL-2 
# Author: Francois Gillet, 23 August 2012
#

"coldiss" <- function(D, nc = 4, byrank = TRUE, diag = FALSE)
{
  require(gclus)
  
  if (max(D)>1) D <- D/max(D)
  
  if (byrank) {
    spe.color <- dmat.color(1-D, cm.colors(nc))
  }
  else {
    spe.color <- dmat.color(1-D, byrank=FALSE, cm.colors(nc))
  }
  
  spe.o <- order.single(1-D)
  speo.color <- spe.color[spe.o, spe.o]
  
  op <- par(mfrow=c(1,2), pty="s")
  
  if (diag) {
    plotcolors(spe.color, rlabels=attributes(D)$Labels, 
               main="Dissimilarity Matrix", 
               dlabels=attributes(D)$Labels)
    plotcolors(speo.color, rlabels=attributes(D)$Labels[spe.o], 
               main="Ordered Dissimilarity Matrix", 
               dlabels=attributes(D)$Labels[spe.o])
  }
  else {
    plotcolors(spe.color, rlabels=attributes(D)$Labels, 
               main="Dissimilarity Matrix")
    plotcolors(speo.color, rlabels=attributes(D)$Labels[spe.o], 
               main="Ordered Dissimilarity Matrix")
  }
  
  par(op)
}

# Usage:
# coldiss(D = dissimilarity.matrix, nc = 4, byrank = TRUE, diag = FALSE)
# If D is not a dissimilarity matrix (max(D) > 1), then D is divided by max(D)
# nc 							number of colours (classes)
# byrank= TRUE		equal-sized classes
# byrank= FALSE		equal-length intervals
# diag = TRUE			print object labels also on the diagonal

# Example:
# coldiss(spe.dj, nc=9, byrank=F, diag=T)

```


```{r, fig.height = 8, fig.width = 16}
coldiss(spe.D.Jac)
```

# Transformations

Communities sampled over homogeneous or short environmental conditions can have species compositions with few zeroes, so that Euclidean distances could be enough to characterize them.

Nevertheless, this is rarely the reality. 

Species may be highly frequent when conditions are favourable, or may be absent from many sites. Sometimes, this skewness may introduce spurious problems to our analyses.

We may then have to transform our composition data to appropriately analyze it.


In `R`, we can rely on `vegan::decostand()` for many types of transformations. 

Take a look into the help of this function to see the available options:

```
?decostand()
```

## Presence-absence transformation


We can change the argument `method` to `"pa"` in `vegdist()` to transform our abundance data into presence-absence data:

<center> If $y_{ij} \geq 1$, then, $y'_{ij} = 1$. </center>

Let us recall our `spe` data set:

```{r}
spe[1:6, 1:6]
``` 

Let us transform `spe` abundances to presence-absences:

```{r}
spe.pa <- decostand(spe, method = "pa")
spe.pa[1:6, 1:6]
```

## Species profiles transformation

Sometimes, one wants to remove the effects of highly abundant units. We can transform the data into profiles of relative species abundances through the following equation:

$$y'_{ij} = \frac{y_{ij}}{y_{i+}}$$

where, $yi+$ indicates the sample total count over all $j=1,…,m$ species, for the $i$-th sample.

In `decostand()`, we can use the `method` with `"total"`:

```{r}
spe.total <- decostand(spe, 
                       method = "total")
spe.total[1:5, 1:6]
```


## Hellinger transformation

We can take the square-root of the _species profile transformation_ and obtain the _Hellinger transformation_, which has very good mathematical properties and allows us to reduce the effects of $y_{ij}$ values that are extremely large.

$$y'_{ij} = \sqrt{\frac{y_{ij}}{y_{i+}}}$$

In `decostand()`, we can use the `method` with `"hellinger"`:

```{r}
spe.total <- decostand(spe, 
                       method = "hellinger")
spe.total[1:5, 1:6]
```

## Z-score standardization

Standardizing environmental variables is crucial as you cannot compare the effects of variables with different units:

```{r, eval = -1}
?decostand
env.z <- decostand(env, method = "standardize")
```

This centres and scales the variables to make your downstream analysis more appropriate:

```{r}
apply(env.z, 2, mean)
apply(env.z, 2, sd)
```

We will see more details about this transformation in the next sections!

#### Little recap

:::: explanation 
**Association -** "general term to describe any measure or coefficient
to quantify the resemblance or difference between objects or
descriptors. In an analysis between descriptors, zero means no
association." (Legendre and Legendre 2012).

**Similarity -** a measure that is "maximum (S=1) when two objects are
identical and minimum when two objects are completely different."
(Legendre and Legendre 2012).

**Distance (also called dissimilarity) -** a measure that is "maximum
(D=1) when two objects are completely different". (Legendre and Legendre
2012). Distance or dissimilarity (D) = 1-S
::::

Choosing an association measure depends on your data, but also on what
you know, ecologically about your data. For example, Euclidean distance
is a very common and easy to use distance measure and is useful for
understanding how different two samples are based on co-occurrence of
species. The way Euclidean distance is calculated though relies on zeros
in the dataset, meaning that two samples or sites without any species in
common may appear more similar than two samples that share a few
species. This could be misleading and it would be best to choose a
different distance measure if you have a lot of zeros in your species
matrix. This is commonly referred to the "double zero" problem in
ordination analyses.

Here are some commonly used dissimilarity (distance) measures (recreated
from Gotelli and Ellison 2004):

  Measure name   Property      Description
  -------------- ------------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Euclidean      Metric        Distance between two points in 2D space.
  Manhattan      Metric        Distance between two points, where the distance is the sum of differences of their Cartesian coordinates, i.e. if you were to make a right able between the points.
  Chord          Metric        This distance is generally used to assess differences due to genetic drift.
  Mahalanobis    Metric        Distance between a point and a set distribution, where the distance is the number of standard deviations of the point from the mean of the distribution.
  Chi-square     Metric        Similar to Euclidean.
  Bray-Curtis    Semi-metric   Dissimilarity between two samples (or sites) where the sum of lower values for species present in both samples are divided by the sum of the species counted in each sample.
  Jaccard        Metric        [Description](http://en.wikipedia.org/wiki/Jaccard_index)
  Sorensen\'s    Semi-metric   Bray-Curtis is 1 - Sorensen

**Quantitative environmental data** Let's look at *associations* between
environmental variables (also known as Q mode):

```{r, echo = TRUE, eval = FALSE}
?dist # this function also compute dissimilarity matrix
env.de<-dist(env.z, method = "euclidean") # euclidean distance matrix of the standardized environmental variables 
windows() #Creates a separate graphical window
coldiss(env.de, diag=TRUE)
```

We can then look at the *dependence* between environmental variables
(also known as R mode):

```{r, echo = TRUE, eval = FALSE}
(env.pearson<-cor(env)) # Pearson r linear correlation
round(env.pearson, 2) #Rounds the coefficients to 2 decimal points 
(env.ken<-cor(env, method="kendall")) # Kendall tau rank correlation
round(env.ken, 2) 
```

The Pearson correlation measures the linear correlation between two
variables. The Kendall tau is a rank correlation which means that it
quantifies the relationship between two descriptors or variables when
the data are ordered within each variable.

In some cases, there may be mixed types of environmental variables. Q
mode can still be used to find associations between these environmental
variables. We'll do this by first creating an example dataframe:

```{r, echo = TRUE, eval = FALSE}
var.g1<-rnorm(30, 0, 1)
var.g2<-runif(30, 0, 5)
var.g3<-gl(3, 10)
var.g4<-gl(2, 5, 30)
(dat2<-data.frame(var.g1, var.g2, var.g3, var.g4))
str(dat2)
summary(dat2)
```

A dissimilarity matrix can be generated for these mixed variables using
the Gower dissimilarity matrix:

```{r, echo = TRUE, eval = FALSE}
?daisy #This function can handle NAs in the data
(dat2.dg<-daisy(dat2, metric="gower"))
coldiss(dat2.dg)
```

**Challenge 1 - Introductory** Discuss with your neighbour: How can we
tell how similar objects are when we have multivariate data? Make a list
of all your suggestions.

**Challenge 1 - Introductory Solution** \<hidden\> Discuss as a group.
\</hidden\>

**Challenge 1 - Advanced** Calculate the Bray-Curtis and the Gower
dissimilarity of species abundance CHA, TRU and VAI for sites 1, 2 and 3
(using the "spe" and "env" dataframes) *without using the decostand()
function.*

**Challenge 1 - Advanced Solution** \<hidden\>

First, it is helpful to know the formula for Bray-Curtis dissimilarity
Bray-Curtis dissimilarity : d\[jk\] = (sum abs(x\[ij\]-x\[ik\]))/(sum
(x\[ij\]+x\[ik\]))

Next, subset the species data so that only sites 1, 2 are included and
only the species CHA, TRU and VAI

```{r, echo = TRUE, eval = FALSE}
spe.challenge<-spe[1:3,1:3] #”[1:3,” refers to rows 1 to 3 while “,1:3]” refers to the first 3 species columns (in #this case the three variables of interest)
```

Determine total species abundance for each site of interest (sum of the
3 rows). This will be for the denominator in the above equation.

```{r, echo = TRUE, eval = FALSE}
(Abund.s1<-sum(spe.challenge[1,]))
(Abund.s2<-sum(spe.challenge[2,]))
(Abund.s3<-sum(spe.challenge[3,]))
#() around code will cause output to print right away in console
```

Now calculate the difference in species abundances for each pair of
sites. For example, what is the difference between the abundance of CHA
and TRU in site 1? You need to calculate the following differences: CHA
and TRU site 1 CHA and VAI site 1 TRU and VAI site 1 CHA and TRU site 2
CHA and VAI site 2 TRU and VAI site 2 CHA and TRU site 3 CHA and VAI
site 3 TRU and VAI site 3

```{r, echo = TRUE, eval = FALSE}
Spec.s1s2<-0
Spec.s1s3<-0
Spec.s2s3<-0
for (i in 1:3) {
  Spec.s1s2<-Spec.s1s2+abs(sum(spe.challenge[1,i]-spe.challenge[2,i]))
  Spec.s1s3<-Spec.s1s3+abs(sum(spe.challenge[1,i]-spe.challenge[3,i]))
  Spec.s2s3<-Spec.s2s3+abs(sum(spe.challenge[2,i]-spe.challenge[3,i])) }
```

Now take the differences you have calculated as the numerator in the
equation for Bray-Curtis dissimilarity and the total species abundance
that you already calculated as the denominator.

```{r, echo = TRUE, eval = FALSE}
(db.s1s2<-Spec.s1s2/(Abund.s1+Abund.s2)) #Site 1 compared to site 2
(db.s1s3<-Spec.s1s3/(Abund.s1+Abund.s3)) #Site 1 compared to site 3
(db.s2s3<-Spec.s2s3/(Abund.s2+Abund.s3)) #Site 2 compared to site 3 
```

You should find values of 0.5 for site 1 to site 2, 0.538 for site 1 to
site 3 and 0.053 for site 2 to 3.

Check your manual results with what you would find using the function
vegdist() with the Bray-Curtis method:

```{r, echo = TRUE, eval = FALSE}
(spe.db.challenge<-vegdist(spe.challenge, method="bray"))
```

A matrix looking like this is produced, which should be the same as your
manual calculations:

           Site 1   Site 2
  -------- -------- --------
  Site 2   0.5      \--
  Site 3   0.538    0.0526

For the Gower dissimilarity, proceed in the same way but use the
appropriate equation: Gower dissimilarity : d\[jk\] = (1/M)
sum(abs(x\[ij\]-x\[ik\])/(max(x\[i\])-min(x\[i\])))

```{r, echo = TRUE, eval = FALSE}
# Calculate the number of columns in your dataset
M<-ncol(spe.challenge)

# Calculate the species abundance differences between pairs of sites for each species
Spe1.s1s2<-abs(spe.challenge[1,1]-spe.challenge[2,1])
Spe2.s1s2<-abs(spe.challenge[1,2]-spe.challenge[2,2])
Spe3.s1s2<-abs(spe.challenge[1,3]-spe.challenge[2,3])
Spe1.s1s3<-abs(spe.challenge[1,1]-spe.challenge[3,1])
Spe2.s1s3<-abs(spe.challenge[1,2]-spe.challenge[3,2])
Spe3.s1s3<-abs(spe.challenge[1,3]-spe.challenge[3,3])
Spe1.s2s3<-abs(spe.challenge[2,1]-spe.challenge[3,1])
Spe2.s2s3<-abs(spe.challenge[2,2]-spe.challenge[3,2])
Spe3.s2s3<-abs(spe.challenge[2,3]-spe.challenge[3,3])

# Calculate the range of each species abundance between sites  
Range.spe1<-max(spe.challenge[,1]) - min (spe.challenge[,1])
Range.spe2<-max(spe.challenge[,2]) - min (spe.challenge[,2])
Range.spe3<-max(spe.challenge[,3]) - min (spe.challenge[,3])

# Calculate the Gower dissimilarity  
(dg.s1s2<-(1/M)*((Spe2.s1s2/Range.spe2)+(Spe3.s1s2/Range.spe3)))
(dg.s1s3<-(1/M)*((Spe2.s1s3/Range.spe2)+(Spe3.s1s3/Range.spe3)))
(dg.s2s3<-(1/M)*((Spe2.s2s3/Range.spe2)+(Spe3.s2s3/Range.spe3)))

# Compare your results
(spe.db.challenge<-vegdist(spe.challenge, method="gower"))
```

# (PART\*) Clustering {-}

# Clustering

One application of association matrices is clustering.
Clustering highlights structures in the data by partitioning either the objects or the descriptors.
As a result, similar objects are combined into groups, allowing distinctions -- or contrasts -- between groups to be identified. 
One goal of ecologists could be to divide a set of sitesinto groups with respect to their environmental conditions or their community composition.

Clustering results are often represented as _dendrograms_ (trees), where
objects agglomerate into groups. 
There are several families of clustering methods, but for the purpose of this workshop, we will
present an overview of three hierarchical agglomerative clustering
methods: single linkage, complete linkage, and Ward's minimum variance
clustering. _See Chapter 8 of Legendre and Legendre 2012 for more details
on the different families of clustering methods._

In hierarchical methods, elements of lower clusters (or groups) become
members of larger, higher ranking clusters, e.g. species, genus, family,
order. Prior to clustering, one needs to create an association matrix
among the objects. Distance matrix is the default choice of clustering
functions in R. The association matrix is first sorted in increasing
distance order (or decreasing similarities). Then, groups are formed
hierarchically following rules specific to each method.

```{r, fig.width=10, echo = FALSE}
# Demonstration of a cluster dendrogram
spe.hel<-decostand(spe, method="hellinger")
spe.dhel <- vegdist(spe.hel,method="euclidean")
spe.dhel.ward <- hclust(spe.dhel, method="ward.D2")
spe.dhel.ward$height<-sqrt(spe.dhel.ward$height)
plot(spe.dhel.ward, hang=-1) # hang=-1 aligns all objets on the same line

```

## Single linkage agglomerative clustering

Let\'s take a simple example of a euclidean distance matrix between 5
objets which were sorted in ascending order.

![](/cluster.example.png){.align-center}

In single linkage agglomerative clustering (also called nearest
neighbour sorting), the objects at the closest distances agglomerate.
The two closest objects agglomerate first, the next two closest
objects/clusters are then linked, and so on, which often generates long
thin clusters or chains of objects (see how objets 1 to 5 cluster
successively). Conversely, in complete linkage agglomerative clustering,
an object agglomerates to a group only when linked to the furthest
element of the group, which in turn links it to all members of that
group (in the above example, the group formed of objets 3 and 4 only
clusters with group 1-2 at 0.4, a distance at which objets 1, 2, 3 and 4
are all linked). As a result, complete linkage clustering will form many
small separate groups, and is more appropriate to look for contrasts,
discontinuities in the data.

## Complete linkage agglomerative clustering

Let's compare the single and complete linkage clustering methods using
the Doubs fish species data.

Species data were already Hellinger-transformed. The cluster analysis
requiring similarity or dissimilarity indices, the first step will be to
generate the Hellinger distance indices.

```{r, echo = TRUE, eval = FALSE}
spe.dhel<-vegdist(spe.hel,method="euclidean") #generates the distance matrix from Hellinger transformed data

#See difference between the two matrices
head(spe.hel)# Hellinger-transformed species data
head(spe.dhel)# Hellinger distances among sites
```

Most clustering methods can be computed with the function hclust() of
the stats package.

```{r, echo = TRUE, eval = FALSE}
#Faire le groupement à liens simples
#Perform single linkage clustering
spe.dhel.single<-hclust(spe.dhel, method="single")
plot(spe.dhel.single)

#Perform complete linkage clustering
spe.dhel.complete<-hclust(spe.dhel, method="complete")
plot(spe.dhel.complete)
```

![](/clust_single.png){.align-center}![](/clust_complete.png){.align-center}

Are there big differences between the two dendrograms?

In single linkage clustering, chains of objets occur (e.g. 19, 29, 30,
20, 26, etc.), whereas more contrasted groups are formed in the complete
linkage clustering.

## Ward's minimum variance clustering

Ward's minimum variance clustering differ from these two methods in that
it clusters objects into groups using the criterion of least squares
(similar to linear models). At the beginning, each object is considered
being a cluster of its own. At each step, the pair of clusters merging
is the one leading to minimum increase in total within-group sum of
squares.

Again, it is possible to generate a Ward's minimum variance clustering
with hclust(). However, the dendogram shows squared distances by
default. In order to compare this dendrogram to the single and complete
linkage clustering results, one must calculate the square root of the
distances.

```{r, echo = TRUE, eval = FALSE}
#Perform Ward minimum variance clustering
spe.dhel.ward<-hclust(spe.dhel, method="ward.D2")
plot(spe.dhel.ward)

#Re-plot the dendrogram by using the square roots of the fusion levels
spe.dhel.ward$height<-sqrt(spe.dhel.ward$height)
plot(spe.dhel.ward)
plot(spe.dhel.ward, hang=-1) # hang=-1 aligns all objets on the same line
```

![](/clust_ward.png){.align-center}
![](/clust_wardfinal.png){.align-center}

The clusters generated using Ward's method tend to be more spherical and
to contain similar numbers of objects.

One must be careful in the choice of an association measure and
clustering method in order to correctly address a problem. What are you
most interested in: gradients? Contrasts? In addition, the results
should be interpreted with respect to the properties of the method used.
If more than one method seems suitable to an ecological question,
computing them all and compare the results would be the way to go. As a
reminder, clustering is not a statistical method, but further steps can
be taken to identify interpretable clusters (e.g. where to cut the
tree), or to compute clustering statistics. Clustering can also be
combined to ordination in order to distinguish groups of sites. These go
beyond the scope of this workshop, but see Borcard et al. 2011 for more
details.